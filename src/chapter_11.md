
# Лекция 11: Самообучение (Self-Supervised Learning)

- [Лекция 11: Самообучение (Self-Supervised Learning)](#лекция-11-самообучение-self-supervised-learning)
  - [1. Введение в самообучение](#1-введение-в-самообучение)
  - [2. Автокодировщики (Autoencoders)](#2-автокодировщики-autoencoders)
  - [3. Самообучение на изображениях (Pretext Tasks for Images)](#3-самообучение-на-изображениях-pretext-tasks-for-images)
  - [4. Контрастное обучение (Contrastive Learning)](#4-контрастное-обучение-contrastive-learning)
  - [5. Векторные представления слов (Word Embeddings)](#5-векторные-представления-слов-word-embeddings)

---

## 1. Введение в самообучение

**1.1. Сценарий**
Проблема: Имеется **много объектов (данных), но мало размеченных меток**. Мы хотели бы эффективно **предобучиться** на объектах без меток, чтобы затем использовать полученные знания для задач с малым количеством размеченных данных.

**1.2. Определения**
*   **Самообучение (Self-Supervised Learning, SSL):** Подход в машинном обучении, при котором для обучения представлений используются задачи, где разметка (метки) генерируется автоматически из самих данных. Это позволяет использовать большие объемы неразмеченных данных. SSL является разновидностью обучения без учителя, но использует "псевдо-метки" для формулирования задачи как обучения с учителем.
*   **Предварительная задача (Pretext Task):** Задача с искусственно созданными метками (псевдо-метками), на которой обучается модель с целью выучить хорошие, обобщающие **представления (representations)** объектов. Сама по себе pretext task может не иметь практической ценности.
*   **Последующая задача (Downstream Task):** Целевая задача (например, классификация, детектирование), для решения которой используются представления, полученные на pretext task. Обычно к "замороженному" или дообучаемому экстрактору признаков (полученному на pretext task) добавляется простой дискриминатор (например, линейный слой или небольшая нейросеть), который обучается на малом количестве размеченных данных для downstream task.

**1.3. Связь с переносом знаний (Transfer Learning)**
(Слайд 5, такой же как в Лекции 1, слайд 41)
1.  **Общая предобучающая модель (Generic Network $A$):** Обучается на большом общем наборе данных $D_A$ для выполнения общей задачи $T_A$ (часто это pretext task в SSL).
2.  **Извлечение признаков (Pre-trained $A'$):** Часть модели $A$ (например, все слои кроме последнего классификационного) используется как экстрактор признаков.
3.  **Обучение на специфической задаче:** Экстрактор $A'$ комбинируется с новой обучаемой частью $B$ (Trainable) и дообучается (или обучается только $B$) на специфическом, часто меньшем, наборе данных $D_B$ для целевой задачи $T_B$.

**1.4. Основные концепции самообучения**
*   **Перенос знаний для извлечения признаков:** SSL – это способ реализовать первый этап переноса знаний (обучение $A$ на $D_A$) без необходимости в человеческой разметке для $D_A$.
*   **Дообучение (Fine-tuning):** Предобученная часть ($A'$) может быть "заморожена" (веса не меняются) или "разморожена" и дообучаться вместе с $B$ на задаче $T_B$ (часто с меньшей скоростью обучения для $A'$).
*   **Дистилляция знаний (Knowledge Distillation - напоминание, слайд 7, как в Лекции 2, слайд 32):**
    Метод, где меньшая "студенческая" модель обучается имитировать выходы (или внутренние представления) большей, предобученной "учительской" модели. Это может использоваться для сжатия моделей или переноса знаний.
    В SSL учительская модель может быть той же архитектуры, но с медленно обновляемыми весами (см. BYOL).
*   **Bootstrap Your Own Latent (BYOL, слайд 8):**
    Метод самообучения, использующий две нейронные сети: **online network** (ученик, параметры $\theta$) и **target network** (учитель, параметры $\xi$).
    1.  Из исходного изображения $x$ создаются два аугментированных представления (view) $v = t(x)$ и $v' = t'(x)$ с помощью функций аугментации $t, t'$.
    2.  **Online network** ($f_\theta, g_\theta, q_\theta$):
        *   $y_\theta = f_\theta(v)$ (representation)
        *   $z_\theta = g_\theta(y_\theta)$ (projection)
        *   $q_\theta(z_\theta)$ (prediction)
    3.  **Target network** ($f_\xi, g_\xi$):
        *   $y'_\xi = f_\xi(v')$
        *   $z'_\xi = g_\xi(y'_\xi)$
    4.  **Задача обучения:** Online network обучается предсказывать выход target network $z'_\xi$. Ошибка: $\text{loss} = ||q_\theta(z_\theta) - z'_\xi||_2^2$.
        Градиент **не** распространяется через target network (операция `sg` - stop-gradient на $z'_\xi$).
    5.  **Обновление учителя:** Параметры target network $\xi$ не обучаются градиентным спуском, а являются экспоненциально скользящим средним параметров online network $\theta$:
        $$ \xi \leftarrow \tau \xi + (1-\tau) \theta $$
        где $\tau$ - коэффициент затухания (например, 0.996).
    *   Архитектуры online и target сетей идентичны.
    *   BYOL не требует негативных примеров, в отличие от многих контрастных методов.

---

## 2. Автокодировщики (Autoencoders)

**2.1. Определение**
**Автокодировщик (autoencoder)** — это нейронная сеть, обучаемая задаче восстановления своего входа на выходе. Цель – выучить полезное **низкоразмерное представление (код, latent representation)** данных путем нелинейной трансформации.

**2.2. Основная идея**
Заставить сеть предсказывать (восстанавливать) то, что подается ей на вход, но с некоторым ограничением, которое не позволяет ей выучить тривиальное тождественное преобразование (просто скопировать вход на выход).

**2.3. Ограничение преобразования**
*   **Структурное ограничение (Недополненный автокодировщик / Undercomplete Autoencoder):**
    Между входным и выходным слоями имеется **скрытый слой с меньшей размерностью**, чем вход/выход. Этот слой называется **"бутылочным горлышком" (bottleneck)**. Сеть вынуждена сжимать информацию во входе в это низкоразмерное представление, сохраняя наиболее важные характеристики.
*   **Регуляризационное ограничение (Разреженный автокодировщик / Sparse Autoencoder):**
    К функции потерь добавляется член регуляризации, который штрафует активации нейронов в скрытом слое (коде), заставляя их быть разреженными (большинство активаций близки к нулю). Размерность кода может быть больше или равна размерности входа.

**2.4. Части автокодировщика**
*   **Кодировщик (Encoder):** Часть сети от входного слоя до "бутылочного горлышка" (скрытого кода $z$). Отображает вход $x$ в код $z = c(x)$.
*   **Декодировщик (Decoder):** Часть сети от "бутылочного горлышка" до выходного слоя. Отображает код $z$ в восстановленный вход $\hat{x} = d(z)$.
*   **Функция потерь:** Обычно среднеквадратичная ошибка между входом $x$ и восстановленным выходом $\hat{x}$: $L(x, \hat{x}) = ||x - d(c(x))||^2$.

**2.5. Модель свёрточного автокодировщика (Convolutional Autoencoder)**
*   Кодировщик состоит из свёрточных слоев и слоев пулинга, уменьшающих пространственную размерность и извлекающих признаки.
*   Декодировщик состоит из слоев, обратных свёртке (транспонированная свёртка или деконволюция) и пулингу (апсемплинг, unpooling), восстанавливающих изображение из латентного представления.

**2.6. Регуляризация для автокодировщика (кроме структурных ограничений)**
Можно добавить регуляризационный член к функции потерь, чтобы наложить дополнительные ограничения на код $c(x)$:
$$ \mathcal{L}(x, d(c(x))) = ||d(c(x)) - x||^2 + \tau \cdot \Omega(c(x)) $$
*   $c$ – кодировщик, $d$ – декодировщик.
*   $\Omega(c(x))$ – член регуляризации (например, $L_1$ норма активаций кода для разреженности, или регуляризатор, заставляющий производную кодировщика быть малой - см. сжимающий автокодировщик).
*   $\tau$ – коэффициент регуляризации.

**2.7. Вариации автокодировщиков**
*   **Разреженный (Sparse) автокодировщик:** Добавляет штраф за неразреженные активации в коде (например, KL-дивергенция между средней активацией нейрона и желаемым низким уровнем разреженности).
*   **Шумоподавляющий (Denoising) автокодировщик (DAE):**
    *   Вход $x$ сначала "портится" (добавляется шум) до $\tilde{x}$.
    *   Кодировщик получает $\tilde{x}$, а декодировщик пытается восстановить **оригинальный, чистый** $x$.
    *   $L(x, d(c(\tilde{x})))$.
    *   Заставляет модель учиться извлекать более робастные признаки, игнорируя шум.
*   **Сжимающий (Contractive) автокодировщик (CAE):**
    К функции потерь добавляется член, штрафующий норму Якобиана кодировщика по входу: $\Omega(c(x)) = ||\nabla_x c(x)||_F^2$.
    Заставляет кодировщик быть менее чувствительным к малым изменениям на входе, т.е. "сжимать" окрестности входных точек в латентном пространстве.
*   **Вариационный (Variational) автокодировщик (VAE):**
    Основан на вероятностных принципах и байесовском выводе. Кодировщик предсказывает параметры распределения (например, среднее $\mu_z$ и дисперсию $\sigma_z^2$ Гауссианы) в латентном пространстве. Код $z$ сэмплируется из этого распределения $q(z|x)$. Декодер $p(x|z)$ также вероятностный. Функция потерь включает член восстановления и член KL-дивергенции между $q(z|x)$ и априорным распределением $p(z)$ (обычно стандартная Гауссиана). (Будет рассмотрен подробнее в лекции о генеративных моделях).

---

## 3. Самообучение на изображениях (Pretext Tasks for Images)

Идея: создать pretext task, где метки можно автоматически сгенерировать из самого изображения.

**3.1. Определение поворота (Rotation Prediction)**
*   **Задача:** Изображение случайным образом поворачивается на один из фиксированных углов (например, 0°, 90°, 180°, 270°). Модель (обычно CNN) должна предсказать, какой поворот был применен.
*   **Псевдо-метка:** Примененный угол поворота (4 класса).
*   Модель учится понимать ориентацию объектов и их общую структуру.

**3.2. Предсказание контекста / Относительного положения патчей (Relative Patch Location)**
*   **Задача:** Из изображения вырезается центральный патч и еще один патч из одного из 8 окружающих его положений. Модель получает оба патча и должна предсказать относительное положение второго патча относительно центрального (8 классов).
*   Модель учится пространственным отношениям между частями объектов.

**3.3. Решение головоломки (Jigsaw Puzzle)**
*   **Задача:** Изображение делится на $N \times N$ патчей (например, 3x3). Патчи случайным образом перемешиваются. Модель должна предсказать исходную перестановку патчей (из $9!$ возможных перестановок, что слишком много; обычно выбирается подмножество перестановок).
*   Модель учится глобальной структуре изображения и взаимному расположению его частей.

**3.4. Что еще? (Другие Pretext Tasks)**
*   **Восстановление части изображения (Image Inpainting):** Часть изображения маскируется, модель должна ее восстановить.
*   **Раскрашивание изображений (Image Colorization):** Модели подается черно-белая версия изображения, она должна предсказать его цветную версию.
*   **Восстановление деталей / Супер-разрешение (Image Super-Resolution):** Модель получает изображение низкого разрешения и должна восстановить его версию высокого разрешения.
*   **Предсказывать слово по контексту (для текста):** См. Masked Language Model (BERT).
*   **Предсказывать контекст по слову (для текста):** См. Skip-gram (Word2Vec).

**3.5. Проблема артефактов: Хроматическая аберрация**
*   **Проблема:** Некоторые pretext tasks могут быть "обмануты" низкоуровневыми артефактами в данных, не связанными с семантикой. Например, из-за особенностей оптики камеры, цветовые каналы (R, G, B) могут быть немного смещены относительно друг друга (хроматическая аберрация). Модель может научиться определять относительное положение частей фотографии по этому сдвигу, а не по семантическому содержанию.
*   **Решение:** Для борьбы с этим можно применять аугментации, которые нивелируют такие артефакты, например, случайно сдвигать цветовые каналы друг относительно друга во время обучения.

---

## 4. Контрастное обучение (Contrastive Learning)

**4.1. Определение**
**Контрастное обучение** – это подход к самообучению, цель которого – научить такие представления (эмбеддинги) объектов, чтобы "похожие" объекты (например, разные аугментированные версии одного и того же объекта – **позитивные пары**) были близки в пространстве представлений, а "непохожие" объекты (случайные другие объекты из датасета – **негативные пары**) были далеки друг от друга.
Это обучение за счет объединения аугментированных или иным образом полученных трансформаций одного объекта в один "класс" с исходным объектом в парадигме метрического обучения или метрической классификации.

**4.2. Пример: использование кропов (вырезанных частей изображения)**
*   Из одного исходного изображения (например, кошки) вырезаются два случайных, но перекрывающихся кропа. Это **позитивная пара**. Их эмбеддинги должны быть "притянуты" (pull together) друг к другу.
*   Кроп из изображения кошки и кроп из совершенно другого изображения (например, собаки) образуют **негативную пару**. Их эмбеддинги должны быть "оттолкнуты" (push apart) друг от друга.
*   Цель: выучить такое векторное представление (эмбеддинг), чтобы части одного объекта были более похожи друг на друга (и на весь объект), чем на любой другой объект.

**4.3. Обучение на одном примере (One-Shot Learning) и нескольких примерах (Few-Shot Learning)**
*   **Сценарий:**
    *   Число классов может увеличиваться со временем (новые классы).
    *   В некоторых (новых) классах может быть очень мало размеченных примеров.
*   **One-Shot Learning:** Алгоритм должен уметь классифицировать объекты нового класса, имея всего **один** размеченный пример этого класса.
*   **Few-Shot Learning:** То же самое, но доступно **несколько** (мало) размеченных примеров нового класса.
*   Контрастное обучение хорошо подходит для предобучения представлений для таких задач, так как оно учит метрику схожести, которая может быть обобщена на новые классы.

**4.4. Добавление центроидов (для One-Shot/Few-Shot классификации)**
*   Обучение на одном примере часто основано на **метрической классификации:** новый объект относится к тому классу, чей "прототип" (центроид) наиболее близок к эмбеддингу этого объекта в выученном пространстве представлений.
*   Когда появляется новый класс с одним/несколькими примерами, эмбеддинг этого примера (или средний эмбеддинг) становится центроидом нового класса.
*   Важно, чтобы выученная метрика (благодаря контрастному или другому SSL обучению) позволяла хорошо разделять классы по их центроидам.

**4.5. Сиамская сеть (Siamese Network)**
*   Состоит из двух (или более) **идентичных подсетей** (с общими весами), которые параллельно обрабатывают два разных входа $x^{(1)}$ и $x^{(2)}$.
*   Каждая подсеть генерирует векторное представление (эмбеддинг) своего входа.
*   Эти два эмбеддинга затем используются для вычисления функции потерь, которая зависит от того, являются ли $x^{(1)}$ и $x^{(2)}$ "похожими" или "непохожими".

**4.6. Triplet Loss**
*   Функция потерь, часто используемая для обучения сиамских сетей или в задачах метрического обучения.
*   Использует тройки примеров:
    *   **Якорь (Anchor, $a$):** Базовый пример.
    *   **Позитивный (Positive, $p$):** Пример того же класса, что и якорь.
    *   **Негативный (Negative, $n$):** Пример другого класса.
*   Цель: расстояние между якорем и позитивным примером $dist(a,p)$ должно быть меньше, чем расстояние между якорем и негативным примером $dist(a,n)$, как минимум на некоторый зазор (margin, $\epsilon$).
    $$ \mathcal{L}(a,p,n) = \max(0, \text{dist}(a,p) - \text{dist}(a,n) + \epsilon) $$
    Если $dist(a,n) > dist(a,p) + \epsilon$, то потери равны нулю.
    В качестве $dist$ может использоваться евклидово расстояние, косинусное расстояние и т.д.

**4.7. Обучение и вывод с Triplet Loss / Сиамскими сетями**
*   **Обучение:** Сеть (кодировщик) обучается по батчам троек $(a,p,n)$ с помощью градиентного спуска, минимизируя Triplet Loss.
*   **Вывод (для классификации, например, One-Shot):**
    *   Для каждого известного класса хранится один или несколько эталонных объектов (центроидов) в виде их эмбеддингов.
    *   Для нового входного объекта вычисляется его эмбеддинг.
    *   Объект классифицируется по ближайшему центроиду (например, по косинусному расстоянию или евклидову).
    *   Чтобы добавить новый класс, его размеченный пример(ы) кодируется, и полученный эмбеддинг (или средний эмбеддинг) становится новым центроидом.

**4.8. Contrastive Language-Image Pre-training (CLIP)**
*   Модель, обучаемая на огромных парах (изображение, текст-описание).
*   Состоит из двух кодировщиков: один для изображений (Image Encoder, обычно CNN или ViT) и один для текста (Text Encoder, обычно Трансформер).
*   **Задача контрастного обучения:**
    *   Для батча из $N$ пар (изображение, текст) создается матрица схожести $N \times N$ между всеми эмбеддингами изображений и всеми эмбеддингами текстов (обычно косинусное сходство).
    *   Цель: максимизировать схожесть "правильных" пар (соответствующее изображение и его описание) и минимизировать схожесть "неправильных" пар (изображение и описание другого изображения).
    *   Функция потерь (симметричная):
        $$ \mathcal{L}(I, T) = -\frac{1}{N} \sum_i \log \frac{\exp(\langle I_i, T_i \rangle / \tau)}{\sum_j \exp(\langle I_i, T_j \rangle / \tau)} - \frac{1}{N} \sum_i \log \frac{\exp(\langle T_i, I_i \rangle / \tau)}{\sum_j \exp(\langle T_i, I_j \rangle / \tau)} $$
        где $\langle \cdot, \cdot \rangle$ - косинусное сходство, $\tau$ - температурный параметр.
        Это похоже на две кросс-энтропийные потери: одна для классификации правильного текста для каждого изображения, другая для классификации правильного изображения для каждого текста.
*   После обучения CLIP может использоваться для **zero-shot классификации изображений**:
    1.  Для каждого класса создается текстовое описание (например, "a photo of a dog").
    2.  Эти описания кодируются текстовым кодировщиком.
    3.  Входное изображение кодируется кодировщиком изображений.
    4.  Изображение классифицируется в тот класс, чье текстовое описание имеет наибольшее косинусное сходство с эмбеддингом изображения.

---

## 5. Векторные представления слов (Word Embeddings)

**5.1. Вопрос о представлении текста**
Модели машинного обучения работают с числовыми данными. Как представить текст (слова, предложения) в виде векторов?

**5.2. One-hot encoding**
*   Фиксируется словарь всех уникальных слов $|V|$.
*   Каждому слову $w$ присваивается уникальный индекс $i(w)$ от $0$ до $|V|-1$.
*   Слово $w$ представляется в виде вектора длины $|V|$, где на позиции $i(w)$ стоит 1, а на всех остальных – 0.
    $$ \text{vector}(w) = (0, \dots, 0, 1_{i(w)}, 0, \dots, 0) $$
*   **Недостатки:**
    *   Очень высокая размерность для больших словарей.
    *   Разреженные векторы.
    *   Не несет семантической информации (все слова ортогональны, т.е. "одинаково не похожи").

**5.3. Основная идея Word2Vec (и других распределенных представлений)**
*   **Дистрибутивная гипотеза (Zellig Harris, 1954):** Слова, встречающиеся в похожих контекстах, вероятно, будут иметь похожий смысл. ("You shall know a word by the company it keeps" - J.R. Firth).
*   **Основная идея:** Характеризовать (представлять) слова через их контексты.

**5.4. Word2Vec: Continuous Bag of Words (CBOW)**
*   **Задача (pretext task):** Предсказать текущее (центральное) слово по его окружающим словам (контексту).
*   **Архитектура:**
    1.  Контекстные слова (например, $w_{t-2}, w_{t-1}, w_{t+1}, w_{t+2}$) представляются своими векторами-эмбеддингами.
    2.  Эмбеддинги контекстных слов агрегируются (например, суммируются или усредняются) для получения вектора контекста.
    3.  Этот вектор контекста используется для предсказания эмбеддинга центрального слова $w_t$.
    4.  Обучаются эмбеддинги слов.
*   **Функция потерь:** Минимизировать отрицательный логарифм вероятности правильного центрального слова при данном контексте:
    $$ L = - \log P(w_i | \text{context}(w_i)) $$

**5.5. Word2Vec: Skip-gram**
*   **Задача (pretext task):** Предсказать окружающие слова (контекст) по текущему (центральному) слову.
*   **Архитектура:**
    1.  Центральное слово $w_t$ представляется своим вектором-эмбеддингом.
    2.  Этот эмбеддинг используется для предсказания эмбеддингов нескольких контекстных слов (например, $w_{t-2}, w_{t-1}, w_{t+1}, w_{t+2}$).
    3.  Обучаются эмбеддинги слов.
*   **Функция потерь:** Минимизировать сумму отрицательных логарифмов вероятностей правильных контекстных слов при данном центральном слове:
    $$ L = - \sum_{c \in \text{context}(w_i)} \log P(c | w_i) $$
    Обычно Skip-gram работает лучше для больших корпусов и редких слов.

**5.6. Как обучить Word2Vec? (Оптимизации)**
Вычисление Softmax по всему словарю (для $P(w_j | \dots)$) очень затратно.
*   **Иерархический Softmax (Hierarchical Softmax):** Словарь организуется в виде двоичного дерева (например, дерево Хаффмана). Вероятность слова вычисляется как произведение вероятностей прохождения по путям в дереве.
*   **Негативное сэмплирование (Negative Sampling):**
    *   Для каждой пары (центральное слово, контекстное слово) из обучающих данных (позитивный пример) генерируется несколько **негативных примеров** путем замены контекстного слова на случайное слово из словаря (не из текущего контекста).
    *   Модель обучается отличать позитивные пары от негативных (бинарная классификация).
    *   Функция потерь для каждой пары $(w, c_{pos})$ и $k$ негативных сэмплов $c_{neg,j}$:
        $$ L = -\log \sigma(\text{score}(w, c_{pos})) - \sum_{j=1}^k \log(1 - \sigma(\text{score}(w, c_{neg,j}))) $$
        где $\text{score}(w,c)$ - это, например, скалярное произведение эмбеддингов $w$ и $c$.
*   **Субсэмплирование часто встречаемых слов:** Очень частые слова (например, "the", "a") несут мало информации о контексте. Они субсэмплируются (выкидываются с некоторой вероятностью), чтобы ускорить обучение и улучшить качество эмбеддингов для более редких слов.

**5.7. Свойства Word2Vec (и других распределенных эмбеддингов)**
*   Слова с похожими значениями имеют близкие векторы в пространстве эмбеддингов (например, "король" и "королева", "собака" и "кот").
*   Обнаруживаются **аналогии** в виде векторной арифметики:
    *   $\text{vec}(\text{"king"}) - \text{vec}(\text{"man"}) + \text{vec}(\text{"woman"}) \approx \text{vec}(\text{"queen"})$
    *   $\text{vec}(\text{"Paris"}) - \text{vec}(\text{"France"}) + \text{vec}(\text{"Italy"}) \approx \text{vec}(\text{"Rome"})$
*   Эти эмбеддинги используются как входные признаки для многих NLP моделей.

---
