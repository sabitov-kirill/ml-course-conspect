
# Лекция 14: Активное обучение и разметка данных

- [Лекция 14: Активное обучение и разметка данных](#лекция-14-активное-обучение-и-разметка-данных)
  - [1. Обучение на частично размеченных данных (Semi-Supervised Learning, SSL)](#1-обучение-на-частично-размеченных-данных-semi-supervised-learning-ssl)
  - [2. Активное обучение (Active Learning)](#2-активное-обучение-active-learning)
  - [3. Гауссовский процесс (Gaussian Process, GP)](#3-гауссовский-процесс-gaussian-process-gp)
  - [4. Другие методы оценки дисперсии (неопределенности)](#4-другие-методы-оценки-дисперсии-неопределенности)
  - [5. Разметка данных](#5-разметка-данных)

---

## 1. Обучение на частично размеченных данных (Semi-Supervised Learning, SSL)

**1.1. Постановка задачи**
*   Тренировочный набор данных состоит из двух частей:
    1.  **$D^l$ (Labeled Data):** Размеченная часть. Объекты содержат как признаки $X$, так и целевую метку $Y$.
    2.  **$D^u$ (Unlabeled Data):** Неразмеченная часть. Объекты содержат только признаки $X$.
*   **Ключевая особенность:** $|D^l| \ll |D^u|$ (размеченных объектов значительно меньше, чем неразмеченных).
*   **Наивное решение:** Выкинуть $D^u$ и обучать модель только на $D^l$. Это один из вариантов работы с пропусками в метках, но он не использует потенциально полезную информацию из $D^u$.
*   **Цель SSL:** Использовать информацию из $D^u$ для улучшения качества модели по сравнению с обучением только на $D^l$.

**1.2. Решения при помощи подходов обучения с учителем**

*   **Самообучение (Self-Training / Pseudo-Labeling):**
    1.  Обучить модель на размеченных данных $D^l$.
    2.  Использовать эту модель для предсказания меток на неразмеченных данных $D^u$.
    3.  Выбрать объекты из $D^u$, для которых модель наиболее уверена в своих предсказаниях (например, предсказания с высокой вероятностью).
    4.  Добавить эти объекты с их "псевдо-метками" в $D^l$.
    5.  Переобучить модель на расширенном $D^l$. Повторять шаги 2-5.
    *   Класс добавляемого объекта определяется предсказанием самого алгоритма.
    *   Риск: если модель ошибается с высокой уверенностью, ошибки могут накапливаться.

*   **Сообучение (Co-Training):**
    *   Используется, если признаки можно разделить на два (или более) **независимых** набора представлений (views), каждый из которых достаточен для классификации.
    1.  Обучаются два (или более) **разных** классификатора на $D^l$, каждый на своем наборе представлений.
    2.  Каждый классификатор делает предсказания на $D^u$.
    3.  Наиболее уверенные предсказания одного классификатора (на его "view") используются для добавления примеров в обучающее множество другого классификатора (на его "view").
    4.  Процесс повторяется.
    *   Идея: разные классификаторы могут "учить" друг друга, используя разные аспекты данных.

*   **Оптимизационный подход (регуляризация на основе неразмеченных данных):**
    Функция потерь модифицируется так, чтобы учитывать неразмеченные данные.
    $$ L(\theta) = L_{class}(a_\theta, D^l) + \lambda \cdot L_{clust}(a_\theta, D^u) $$
    *   $L_{class}$: стандартная функция потерь для обучения с учителем на $D^l$.
    *   $L_{clust}$: член, который поощряет выполнение некоторых предположений о структуре данных на $D^u$ (например, кластерное предположение – точки в одном кластере должны иметь одинаковые метки, или предположение о многообразии – разделяющая поверхность не должна проходить через области высокой плотности данных).
    *   $\lambda$: коэффициент, балансирующий вклад двух членов.

**1.3. Semi-Supervised Support Vector Machine (S3VM / Transductive SVM)**
*   Модификация SVM для SSL.
*   Цель: найти разделяющую гиперплоскость, которая не только хорошо разделяет размеченные данные $D^l$, но и проходит через области низкой плотности неразмеченных данных $D^u$ (максимизирует зазор и для неразмеченных данных).
*   Функция потерь (один из вариантов):
    $$ \sum_{i=1}^l (1 - M_i(w, w_0))_+ + \frac{1}{2C} ||w||^2 + \sum_{j=1}^u (1 - |M_j(w, w_0)|)_+ \rightarrow \min_{w,w_0} $$
    *   Первый член – стандартный hinge loss для $D^l$. $M_i(w, w_0) = y_i(\langle w, x_i \rangle + w_0)$.
    *   Второй член – регуляризация.
    *   Третий член – штраф для неразмеченных данных, заставляющий их быть как можно дальше от разделяющей гиперплоскости (т.е. $|M_j(w, w_0)| \ge 1$).
    *   $(x)_+ = \max(0,x)$.
*   Задача оптимизации для S3VM обычно невыпуклая и сложная.

**1.4. Решения при помощи обучения без учителя**

*   **Решение при помощи извлечения признаков (Feature Extraction):**
    1.  Обучить на **всех данных** ($D^l \cup D^u$) алгоритм извлечения признаков без учителя (например, автокодировщик, PCA, t-SNE для визуализации). Получаем новые представления $\hat{X}$ из исходных $X$.
    2.  Обучить на **размеченной части** $D^l$ (с новыми признаками $\hat{X}^l$) стандартный алгоритм обучения с учителем для отображения $\hat{X}^l \rightarrow Y$.
    *   Это более "умный" способ работы с пропущенными метками, так как структура неразмеченных данных используется для построения лучшего пространства признаков.

*   **Решение при помощи кластеризации:**
    1.  Обучить на **всех данных** ($D^l \cup D^u$) алгоритм кластеризации для получения меток кластеров $\hat{Y}$ (например, $X \rightarrow \hat{Y}$).
    2.  Обучить на **размеченной части** $D^l$ алгоритм обучения с учителем для отображения меток кластеров $\hat{Y}^l$ (или исходных признаков $X^l$ вместе с $\hat{Y}^l$) в истинные метки $Y$.
    *   Предположение: кластеры в пространстве признаков соответствуют классам.

**1.5. Пример для MNIST (слайд 8)**
*   Визуализация (например, t-SNE) данных MNIST без использования информации о классах показывает, что цифры образуют достаточно хорошо различимые кластеры.
*   Для определения, какому классу соответствует каждый кластер, достаточно нескольких размеченных объектов из этого кластера.

**1.6. Модификация методов кластеризации для SSL**
*   **EM-подобные алгоритмы (например, Gaussian Mixture Models):**
    *   На E-шаге (оценка скрытых переменных – принадлежности к компонентам смеси) для объектов из $D^l$ с известным классом, их принадлежность к компонентам (соответствующим их классу) фиксируется и не изменяется.
*   **Агломеративная кластеризация:**
    *   Можно ввести ограничение: не объединять кластеры, если они содержат размеченные объекты из разных классов.

---

## 2. Активное обучение (Active Learning)

**2.1. Сценарий**
*   Есть доступ к большому объему неразмеченных данных.
*   Разметка данных – дорогостоящий и/или медленный процесс (требует участия человека-эксперта, "Оракула").
*   Скорость обучения моделей может быть выше скорости разметки.

**2.2. Определение**
*   **Активное обучение:** Подход, в котором алгоритм сам выбирает, какие из неразмеченных объектов наиболее информативны для разметки, чтобы максимально улучшить качество модели при минимальных затратах на разметку.
*   Условия схожи с SSL, но здесь алгоритм может **задавать Оракулу вопросы** о метках выбранных объектов.
*   **Задача:** Найти оптимальную стратегию запросов к Оракулу, которая максимизирует качество аппроксимации $X \rightarrow Y$ при наименьшем числе обращений (размеченных примеров).
*   **Наивное решение:** Отправлять на разметку случайные объекты (это соответствует пассивному обучению / supervised learning с ограниченным бюджетом на разметку).

**2.3. Оценка алгоритмов активного обучения**
*   **Тестовое множество должно состоять из случайно выбранных объектов**, чтобы не было смещения в оценке.
*   **Метрики для сравнения:**
    *   Качество модели (например, точность) при **фиксированном бюджете** на разметку (фиксированном числе обращений к Оракулу).
    *   Число обращений (стоимость разметки), необходимое для достижения **заданного уровня качества**.
    *   **Площадь под кривой обучения (Area Under the Learning Curve, AULC):** Кривая показывает зависимость качества модели от числа размеченных примеров. Большая площадь означает более эффективное обучение.
*   Использование тренировочного множества (размеченного в процессе активного обучения) для оценки неинформативно, так как оно будет смещенным и разным для разных стратегий.

**2.4. Стратегии выбора объектов для разметки (Query Strategies)**

*   **Выбор по степени неуверенности (Uncertainty Sampling):**
    Идея: запрашивать метки для тех объектов, в предсказаниях которых модель наименее уверена.
    Пусть $P_\theta(y|x)$ – вероятность класса $y$ для объекта $x$ по текущей модели с параметрами $\theta$. Пусть $\hat{y} = \arg\max_y P_\theta(y|x)$ – наиболее вероятный класс.
    *   **Минимальная уверенность (Least Confident / Min Confidence):**
        Выбирается объект $x^*_{LC} = \arg\max_x (1 - P_\theta(\hat{y}|x))$.
        (Эквивалентно $\arg\min_x P_\theta(\hat{y}|x)$).
    *   **Отбор по минимальному отступу (Margin Sampling):**
        Выбирается объект, для которого разница между вероятностями двух наиболее вероятных классов $(\hat{y}_1, \hat{y}_2)$ минимальна.
        $$ x^*_{MS} = \arg\min_x (P_\theta(\hat{y}_1|x) - P_\theta(\hat{y}_2|x)) $$
        (Или $\arg\max_x$ для $-(P_\theta(\hat{y}_1|x) - P_\theta(\hat{y}_2|x))$ как на слайде).
    *   **Максимальная энтропия (Maximum Entropy):**
        Выбирается объект, для которого энтропия распределения вероятностей по классам максимальна (наибольшая неопределенность).
        $$ x^*_{ME} = \arg\max_x \left( - \sum_i P_\theta(y_i|x) \log P_\theta(y_i|x) \right) $$

*   **Пример для одномерного SVM (слайд 16):**
    На каждом шаге на разметку отправляется неразмеченный объект, наиболее близкий к текущей разделяющей гиперплоскости (т.е. где модель наименее уверена). Это похоже на бинарный поиск оптимальной границы.

*   **Отбор по несогласию в комитете (Query-by-Committee, QBC):**
    *   Используется комитет (ансамбль) из $C$ моделей $\{ \theta_{(1)}, \dots, \theta_{(|C|)} \}$, обученных на текущих размеченных данных (например, с помощью bagging или разных инициализаций).
    *   **Идея:** Запрашивать метки для тех объектов, по которым предсказания моделей в комитете наиболее сильно расходятся (наименьшее согласие).
    *   **Меры несогласия:**
        *   **Энтропия голосования (Vote Entropy):**
            $$ x^*_{VE} = \arg\max_{x \in H} \left( - \sum_i \frac{V(y_i)}{|C|} \log \frac{V(y_i)}{|C|} \right) $$
            где $V(y_i)$ – число голосов (моделей в комитете), предсказавших метку $y_i$ для объекта $x$.
        *   **KL-дивергенция:** Средняя KL-дивергенция между распределением вероятностей, предсказанным каждой моделью, и средним распределением вероятностей по комитету.

*   **Ожидаемое изменение модели (Expected Model Change):**
    *   **Идея:** Запрашивать метки для тех объектов, которые, как ожидается, приведут к наибольшему изменению параметров модели (или ее ошибки).
    *   Изменение модели можно оценивать, например, как ожидаемую норму градиента функции потерь, если бы этот объект был добавлен в обучающий набор:
        $$ x^*_{EGL} = \arg\max_x \sum_i P_\theta(y_i|x) ||\nabla \mathcal{L}(x, y_i; \theta)|| $$
        (Суммирование по всем возможным меткам $y_i$ для объекта $x$, взвешенное по их текущей вероятности).

*   **Ожидаемое сокращение ошибки (Expected Error Reduction):**
    *   **Идея:** Запрашивать метки для тех объектов, которые, как ожидается, приведут к наибольшему уменьшению ошибки на неразмеченных данных.
    *   **Минимизация ожидания 0/1 ошибки (точности):**
        $$ x^*_{0/1} = \arg\max_x \sum_i P_\theta(y_i|x) \sum_{x' \in D^u} (1 - P_{\theta+(x,y_i)}(\hat{y}|x')) $$
        где $P_{\theta+(x,y_i)}$ – модель, переобученная с добавлением $(x, y_i)$. Это очень ресурсоемко.
    *   **Минимизация ожидания перекрестной энтропии:**
        $$ x^*_{CE} = \arg\max_x \sum_i P_\theta(y_i|x) \left( - \sum_j \sum_{x' \in D^u} P_{\theta+(x,y_i)}(y_j|x') \log P_{\theta+(x,y_i)}(y_j|x') \right) $$

*   **Сэмплирование с учётом плотности (Density-Weighted Sampling):**
    *   **Проблема uncertainty sampling:** Может выбирать аномалии (outliers), которые малоинформативны для основной массы данных.
    *   **Идея:** Модифицировать меру неуверенности, домножая ее на оценку плотности распределения данных $p(x)$. Это позволяет выбирать объекты, которые не только неопределенны, но и репрезентативны (находятся в плотных областях).
    *   **Пакетная разметка (Batch Active Learning):**
        *   Отправлять на разметку по одному объекту может быть неэффективно (если Оракул может размечать пакетами).
        *   Если просто выбрать $k$ самых неуверенных объектов, они могут быть очень похожи друг на друга (находиться в одной области неопределенности).
        *   Учет плотности или меры разнообразия (diversity) помогает выбирать информативные и разнообразные объекты для пакетной разметки.

---

## 3. Гауссовский процесс (Gaussian Process, GP)

**3.1. Определение**
*   **Гауссовский процесс** – это стохастический процесс (коллекция случайных величин, индексированных временем или пространством), такой что любой конечный набор этих случайных величин имеет совместное многомерное нормальное (Гауссовское) распределение.
*   Любая конечная линейная комбинация этих случайных величин также нормально распределена.
*   GP является обобщением многомерного Гауссовского распределения на бесконечномерное пространство функций.
*   Полностью определяется **функцией среднего $m(x)$** и **ковариационной функцией (ядром) $k(x, x')$**:
    $$ f(x) \sim GP(m(x), k(x,x')) $$
    $m(x) = \mathbb{E}[f(x)]$
    $k(x,x') = \mathbb{E}[(f(x)-m(x))(f(x')-m(x'))]$
*   Традиционно используется в **байесовской оптимизации** в качестве суррогатной модели для аппроксимации дорогой целевой функции.

**3.2. Получение предсказания с помощью GP (для регрессии)**
Пусть у нас есть обучающий набор $(X, \mathbf{y}) = \{(x_i, y_i)\}_{i=1}^N$. Мы хотим предсказать значение $f(x^*)$ в новой точке $x^*$.
*   Совместное распределение $y_1, \dots, y_N, f(x^*)$ является Гауссовским.
*   Предсказание (среднее апостериорного распределения $p(f(x^*)|X, \mathbf{y}, x^*)$):
    $$ \mu(x^*) = m(x^*) + \mathbf{k}(x^*)^T (K + \sigma_n^2 I)^{-1} (\mathbf{y} - \mathbf{m}(X)) $$
    *   $K$: ковариационная матрица для обучающих точек, $K_{ij} = k(x_i, x_j)$.
    *   $\mathbf{k}(x^*)$: вектор ковариаций между $x^*$ и обучающими точками, $k_i(x^*) = k(x_i, x^*)$.
    *   $\sigma_n^2$: дисперсия шума в наблюдениях $y_i$ (если предполагается).
    *   $\mathbf{m}(X)$: вектор априорных средних для обучающих точек. Часто $m(x)=0$.
*   Дисперсия предсказания (неопределенность):
    $$ \sigma^2(x^*) = k(x^*, x^*) - \mathbf{k}(x^*)^T (K + \sigma_n^2 I)^{-1} \mathbf{k}(x^*) $$
*   Матрица $(K + \sigma_n^2 I)^{-1}$ не зависит от запроса $x^*$ и может быть предподсчитана.

**3.3. Ковариационные функции (Ядра)**
Определяют свойства функций, которые могут быть смоделированы GP (гладкость, периодичность и т.д.).
*   Похожи на ядра в методе опорных векторов (SVM).
*   **Константа:** $k(a,b) = C$.
*   **Линейная:** $k(a,b) = \langle a, b \rangle$. (Если данные центрированы, это обычная ковариация).
*   **Квадратичная экспоненциальная (Squared Exponential / RBF Kernel):**
    $$ k(a,b) = \sigma_f^2 \exp \left( -\frac{1}{2l^2} ||a-b||^2 \right) $$
    Или в более общем виде с матрицей масштабирования $\Theta$:
    $$ k(a,b) = \exp \left( -\frac{1}{2} (a-b)^T \Theta^{-2} (a-b) \right) $$
    *   $\sigma_f^2$: амплитуда.
    *   $l$ или $\Theta$: характерные масштабы длины.
*   Множество других: Матерн, периодические, рационально-квадратичные и т.д. Ядра можно комбинировать (сумма, произведение).

**3.4. Сэмплирование Томпсона (Thompson Sampling) с GP**
*   Гауссовский процесс определяет распределение над функциями.
*   На каждом шаге байесовской оптимизации или активного обучения можно **сэмплировать случайную функцию** $f_s$ из текущего апостериорного распределения GP.
*   Затем выбрать следующую точку для запроса, максимизируя эту сэмплированную функцию $f_s(x)$.
*   Это один из способов балансировки исследования и использования.

---

## 4. Другие методы оценки дисперсии (неопределенности)

Неопределенность предсказаний модели важна для многих стратегий активного обучения (например, UCB в байесовской оптимизации, uncertainty sampling).

**4.1. Оценка дисперсии ансамблем моделей**
*   Рассмотрим ансамбль из $T$ моделей: $a_1, a_2, \dots, a_T$.
*   Пусть предсказание ансамбля $y(x)$ вычисляется как среднее предсказаний отдельных моделей:
    $$ y(x) = \mathbb{E}_i [a_i(x)] = \frac{1}{T} \sum_{i=1}^T a_i(x) $$
*   Тогда дисперсию $\sigma^2(x)$ предсказания ансамбля можно оценить как выборочную дисперсию ответов моделей:
    $$ \sigma^2(x) = \mathbb{D}_i [a_i(x)] = \frac{1}{T-1} \sum_{i=1}^T (a_i(x) - y(x))^2 $$
    Чем больше разброс предсказаний моделей ансамбля, тем выше неопределенность.

**4.2. Случайный лес (Random Forest)**
*   Ансамбль деревьев принятия решений.
*   **Деревья принятия решений:**
    *   Умеют работать с объектами со смешанными типами признаков (числовые, категориальные).
    *   Быстро обучаются и делают предсказания.
    *   Не сильно переобучаются при большом числе признаков (особенно в составе леса).
    *   **Плохо экстраполируют** за пределы диапазона значений признаков, виденных на обучении.
*   Случайный лес может использоваться как суррогатная модель в байесовской оптимизации или для оценки неопределенности. Предсказание – среднее по деревьям, неопределенность – дисперсия по деревьям.
*   **Сравнение с GP (слайд 29):**
    *   Случайный лес хуже экстраполирует функцию по сравнению с GP.
    *   Оценка неопределенности случайным лесом также может быть хуже, особенно вне областей с данными.
    *   В середине (где мало точек) предсказания также могут быть хуже.

**4.3. Случайное отключение в нейронных сетях (Dropout для оценки неопределенности)**
*   **На стадии обучения:** Dropout случайным образом отключает нейроны (или их выходы).
*   Это можно представить как обучение ансамбля множества "прореженных" сетей с общими параметрами.
*   **На стадии предсказания (стандартно):** Dropout отключается, и используется вся сеть (с масштабированием весов или активаций).
*   **Для оценки дисперсии (Monte Carlo Dropout):**
    *   На стадии предсказания Dropout **не отключается**.
    *   Делается несколько (например, $T$) прогонов через сеть с **разными масками Dropout** для одного и того же входа $x$.
    *   Получаем $T$ разных предсказаний $\{y_1(x), \dots, y_T(x)\}$.
    *   Среднее этих предсказаний используется как итоговое предсказание.
    *   Выборочная дисперсия этих предсказаний используется как оценка неопределенности модели (эпистемической неопределенности).

---

## 5. Разметка данных

**5.1. Ограничения процесса разметки**
*   **Модальность данных:** Людям (разметчикам) трудно размечать абстрактные векторы чисел. Разметка обычно выполняется для понятных модальностей: картинки, звук, видео, текст.
*   **Квалификация и оборудование:** Для некоторых задач разметки требуется специальная квалификация (например, медицинская диагностика) и/или оборудование.
*   **Предварительная разметка:** Часть данных (золотой стандарт) должна быть предварительно размечена экспертами для обучения и контроля качества других разметчиков.
*   **Точность и стабильность:** Нет гарантии, что люди будут размечать абсолютно точно и стабильно (согласие между разметчиками - inter-annotator agreement).
*   **"Спорные" объекты:** При активном обучении на разметку часто отправляются "спорные" или пограничные объекты, которые сложны для разметки даже для человека.

**5.2. Инструменты для разметки данных**
Существует множество инструментов для различных типов данных и задач.
*   **`ipyannotate` (слайд 33):** Библиотека Python для создания простых виджетов разметки в Jupyter Notebook. Подходит для небольших задач и экспериментов.
*   **CVAT (Computer Vision Annotation Tool, слайд 34):** Мощный веб-инструмент с открытым исходным кодом для разметки изображений и видео (классификация, детектирование, сегментация, трекинг).
*   **YEDDA (слайд 35):** Легковесный инструмент для аннотирования текстовых фрагментов (span annotation) для задач типа извлечения именованных сущностей (NER).
*   **Stanford CoreNLP (слайд 36):** Набор инструментов для обработки естественного языка, включающий возможности для аннотирования (части речи, именованные сущности, синтаксические зависимости).
*   **EchoML (слайд 37):** Инструмент для разметки аудиоданных (например, для распознавания звуковых событий).
*   Множество коммерческих платформ (Toloka, Amazon Mechanical Turk, Labelbox, Scale AI и др.), которые предоставляют интерфейсы для разметки и доступ к пулу разметчиков.

**5.3. Слабая разметка (Weak Supervision)**
Использование менее точных или косвенных источников информации для получения меток, когда точная разметка дорога или невозможна.
*   **Слабая разметка** – это разметка для более простой, связанной задачи, которая может помочь в решении основной, более сложной задачи.
*   **Примеры:**
    *   Для задачи классификации: использовать вероятностные метки (soft labels) вместо жестких one-hot.
    *   Для задачи мультиклассовой (multi-label) классификации: использовать метки на уровне всего изображения (знать, что на картинке есть "кошка" и "собака", но не их точное положение) для обучения детектора объектов.
    *   Для задачи детекции объектов: использовать метки на уровне всего изображения для задачи сегментации (если известно, что объект есть, то хотя бы часть пикселей должна быть отнесена к нему).

**5.4. Уточнение разметки (Iterative Annotation / Refinement)**
Процесс улучшения качества разметки.
*   Сегментацию можно заменить на более простую детекцию (разметка ограничивающих рамок вместо попиксельных масок).
*   При выделении объекта можно просить разметчиков уточнять края (например, с помощью интерактивной сегментации).
*   Вместо построения обводки объекта с нуля, можно предложить разметчику скорректировать существующую (возможно, предсказанную моделью) обводку.

**5.5. Контроль качества разметки**
*   **Золотой стандарт (Gold Standard / Honeypots):** В задания для разметчиков подмешиваются объекты с уже известной (эталонной) разметкой. Это позволяет оценить качество работы каждого разметчика.
*   **Перекрытие (Overlap / Redundancy):** Один и тот же объект размечается несколькими (например, 3-5) разными людьми.
    *   Позволяет вычислить **межэкспертное согласие (inter-annotator agreement, IAA)**, например, с помощью каппы Коэна или альфы Криппендорфа.
    *   Помогает выявить спорные или неоднозначные объекты.
    *   Итоговая метка может быть выбрана голосованием большинства или более сложными методами агрегации.
*   **Задача проверки качества как задача разметки:** Проверка уже выполненной разметки может быть представлена как отдельная задача для других (возможно, более квалифицированных) разметчиков.

---
