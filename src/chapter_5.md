
# Лекция 5: Свёрточные сети и работа с изображениями

- [Лекция 5: Свёрточные сети и работа с изображениями](#лекция-5-свёрточные-сети-и-работа-с-изображениями)
  - [1. Особенности изображений](#1-особенности-изображений)
  - [2. Свёрточные сети (Convolutional Neural Networks, CNNs)](#2-свёрточные-сети-convolutional-neural-networks-cnns)
  - [3. Обзор архитектур CNN](#3-обзор-архитектур-cnn)
  - [4. Задачи компьютерного зрения](#4-задачи-компьютерного-зрения)

---

## 1. Особенности изображений

**1.1. Кодирование изображения**
*   Цветное изображение обычно представляется как трёхмерный тензор (матрица) с измерениями: **ширина (width) × высота (height) × глубина (depth/channels)**.
    *   Глубина обычно соответствует цветовым каналам (например, 3 для RGB: Red, Green, Blue).
    *   Для черно-белых изображений глубина равна 1.
*   Простое "вытягивание" матрицы пикселей в один длинный вектор признаков (как для полносвязных сетей) приводит к потере важной пространственной информации и инвариантов (например, инвариантность к сдвигу, локальность связей).

**1.2. Аугментация данных (Data Augmentation)**
Искусственное увеличение размера обучающего набора данных путем применения различных преобразований к существующим изображениям. Это помогает модели стать более робастной и уменьшает переобучение.
*   **Примеры аугментаций:**
    *   **Горизонтальное отражение (Horizontal Flip):** Зеркальное отражение изображения.
    *   **Кадрирование (Crop):** Вырезание случайной или центральной части изображения.
    *   **Изменение контраста (Contrast).**
    *   **Изменение цветового пространства (Hue / Saturation / Value).**
    *   **Размытие (Median Blur, Gaussian Blur).**
    *   **Гамма-коррекция (Gamma).**
    *   Повороты, масштабирование, сдвиги, добавление шума и т.д.

**1.3. Краткая история компьютерного зрения (подходы к извлечению признаков)**
1.  **Handcrafted Features + Predictor:** Ручное создание признаков (SIFT, SURF, HOG) и последующее использование классического классификатора (SVM, Logistic Regression).
2.  **Handcrafted Features + Kernel Embedding + Predictor:** Использование ядерных методов для улучшения представления признаков.
3.  **Handcrafted Features + Kernel Embedding + Metric Learning + Predictor:** Обучение метрики для улучшения разделения классов в пространстве признаков.
4.  **Deep Learning (End-to-End):** Нейронная сеть сама обучается извлекать иерархические признаки из сырых пикселей и выполнять предсказание.

**1.4. Основные концепции свёрточных сетей**
*   **Локальное восприятие (Local Receptive Fields):** Каждый нейрон (или фильтр) обрабатывает только небольшую локальную область входного тензора. Это отражает тот факт, что пиксели, близкие друг к другу, обычно сильно коррелируют и формируют локальные структуры (грани, углы, текстуры).
*   **Общие параметры (Shared Weights / Parameter Sharing):** Один и тот же набор весов (ядро/фильтр) применяется ко всем локальным областям входного изображения. Это позволяет:
    *   Значительно уменьшить количество настраиваемых параметров по сравнению с полносвязными сетями.
    *   Обнаруживать один и тот же признак (например, вертикальную линию) в разных частях изображения. Это обеспечивает **инвариантность к сдвигу**.
*   **Субдискретизация / Пулинг (Subsampling / Pooling):** Уменьшение пространственной размерности карт признаков. Это помогает:
    *   Сделать представление более компактным и робастным к небольшим сдвигам и искажениям (инвариантность к масштабированию и локальным деформациям).
    *   Увеличить "поле зрения" последующих слоев.

---

## 2. Свёрточные сети (Convolutional Neural Networks, CNNs)

**2.1. Обработка изображений свёртками (классические фильтры)**
Свёртка – это математическая операция, широко используемая в обработке сигналов и изображений. Применение различных ядер (фильтров) к изображению позволяет выделять различные характеристики:
*   **Размытие (Blur):** Усредняющее ядро.
*   **Повышение резкости (Sharpen):** Ядро, подчеркивающее различия между соседними пикселями.
*   **Выделение границ (Edge Detection):** Ядра, реагирующие на перепады яркости (например, фильтр Собеля, Лапласиан).

**2.2. Дискретная свёртка**
Для двумерного изображения $x$ и ядра $k$, операция свёртки $(x * k)$ в точке $(i,j)$ вычисляется как:
$$ (x * k)_{ij} = \sum_{p,q} x_{i+p, j+q} \cdot k_{r-p, r-q} $$
Чаще на практике используется **кросс-корреляция**, где ядро не переворачивается:
$$ (x \star k)_{ij} = \sum_{p,q} x_{i+p, j+q} \cdot k_{p,q} $$
В контексте нейронных сетей, поскольку ядра обучаемы, разница между свёрткой и кросс-корреляцией нивелируется (сеть может выучить "перевернутое" ядро).

**2.3. Свёртка 1D массива**
Свёртка массива $m$ (сигнал) с помощью ядра $a$ (фильтр) для получения массива $n$:
$$ n[k] = (m * a)[k] = \sum_{i=-w}^{w} m[k+i] \cdot a[i+w] $$
(Формула на слайде $n[k] = \sum_{i=-w}^{w} m[k+i] \cdot a[i+w]$ предполагает, что центр ядра $a$ находится в $a[w]$ и его полуширина $w$).
Более общая форма для дискретной свёртки:
$$ (m * a)[k] = \sum_{i=-\infty}^{\infty} m[i] \cdot a[k-i] $$

**2.4. Свойства свёрток**
*   **Ассоциативность:** $(f * g) * h = f * (g * h)$
*   **Коммутативность:** $f * g = g * f$
*   **Линейность:** $f * (\alpha g + \beta h) = \alpha (f * g) + \beta (f * h)$

**2.5. Дополнения (Padding)**
Чтобы ядро свёртки могло обрабатывать пиксели на границах изображения и чтобы выходная карта признаков имела желаемый размер (например, тот же, что и входная), входное изображение часто дополняется по краям.
*   **Нулевой паддинг (Zero Padding):** Добавление нулей.
*   **Расширение границ (Border Extension / Replication Padding):** Копирование крайних пикселей.
*   **Зеркальный паддинг (Reflection Padding):** Зеркальное отражение пикселей относительно границы.
*   **Циклический паддинг (Circular Padding / Wrap Around):** "Заворачивание" изображения.

**2.6. 2D свёртка в CNN**
Центральный элемент ядра накладывается на текущий пиксель входной карты признаков. Значение соответствующего пикселя выходной карты признаков вычисляется как взвешенная сумма пикселей входной карты, попадающих под ядро.

**2.7. Свёрточные тензоры (работа с многоканальными изображениями)**
*   Входное изображение (например, RGB) имеет несколько каналов (глубину).
*   Свёрточное ядро также имеет глубину, соответствующую глубине входного тензора (например, для RGB входа ядро будет иметь размер $K_w \times K_h \times 3$).
*   Каждый фильтр (набор таких ядер) производит одну 2D карту признаков на выходе. Если используется $F$ фильтров, выходной тензор будет иметь $F$ каналов.
*   **Input Layer:** $[H \times W \times C_{in}]$ (например, $H \times W \times 3$ для RGB)
*   **Convolutional Layer Output:** $[H_{out} \times W_{out} \times F]$ (где $F$ - число фильтров)

**2.8. Языковой нюанс (терминология)**
*   **Фильтры:** Параметры свёрточного преобразования (ядра) иногда называют фильтрами, хотя они не "фильтруют" в классическом смысле, а обучаются выделять признаки.
*   **Карты признаков (Feature Maps):** Выходные тензоры свёрточных слоев (результат применения фильтров).

**2.9. Размер карты признаков после свёртки**
Для входного изображения шириной $I$, ядра шириной $K$, паддинга $P$ (с каждой стороны) и шага (stride) $S$:
$$ O = \frac{I - K + 2P}{S} + 1 $$
Эта формула применяется независимо к ширине и высоте.

**2.10. Пулинг (Pooling / Subsampling)**
Операция уменьшения пространственной размерности карт признаков.
*   **Цели:**
    *   Снижение вычислительной сложности.
    *   Обеспечение инвариантности к небольшим сдвигам и деформациям.
    *   Увеличение рецептивного поля последующих слоев.
*   **Типы пулинга:**
    *   **Max Pooling:** В каждой локальной области выбирается максимальное значение.
    *   **Average Pooling:** Вычисляется среднее значение в локальной области.
*   Пулинг также применяется с некоторым размером окна и шагом.
*   Пулинг может "декоррелировать" нейроны, заставляя их реагировать на более общие признаки.

**2.11. Размер карты признаков после пулинга**
Для входной карты шириной $I$, окна пулинга шириной $P_s$ и шага $S$:
$$ O = \frac{I - P_s}{S} + 1 $$
(Здесь $P_s$ - это размер окна пулинга, не паддинг).

**2.12. Визуализация активаций слоёв**
*   **Ранние слои:** Фильтры обучаются распознавать простые низкоуровневые признаки: грани, углы, цветовые пятна, простые текстуры.
*   **Средние слои:** Комбинируют признаки из предыдущих слоев для распознавания более сложных паттернов: части объектов (глаза, колеса), более сложные текстуры.
*   **Глубокие слои:** Распознают целые объекты или их крупные фрагменты. Признаки становятся более абстрактными и семантически значимыми.

---

## 3. Обзор архитектур CNN

**3.1. Неокогнитрон (Neocognitron, Фукусима, 1980)**
*   Одна из самых ранних архитектур, вдохновленных зрительной корой.
*   Состояла из чередующихся S-слоев (simple cells, аналог свёрточных) и C-слоев (complex cells, аналог пулинга).
*   Демонстрировала иерархическое извлечение признаков.

**3.2. LeNet (LeCun et al., 1998)**
*   Одна из первых успешных CNN, применявшихся для распознавания рукописных цифр (набор MNIST).
*   Архитектура: Вход $\rightarrow$ Conv1 $\rightarrow$ Pool1 $\rightarrow$ Conv2 $\rightarrow$ Pool2 $\rightarrow$ FC1 $\rightarrow$ FC2 $\rightarrow$ Выход (Softmax).
    *   Conv слои использовали сигмоидную или гиперболическую тангенс функцию активации.
    *   Pool слои – average pooling.
*   Ключевые идеи: иерархическая структура, общие веса, обратное распространение ошибки для обучения.
*   Пример последовательности тензоров в LeNet-5 (слайд 16):
    *   Вход: $32 \times 32 \times 1$
    *   C1 (Conv, 6 фильтров 5x5, stride 1): $28 \times 28 \times 6$
    *   S2 (Pool, 2x2, stride 2): $14 \times 14 \times 6$
    *   C3 (Conv, 16 фильтров 5x5, stride 1): $10 \times 10 \times 16$
    *   S4 (Pool, 2x2, stride 2): $5 \times 5 \times 16$ (это 400 нейронов)
    *   C5 (FC, 120 нейронов)
    *   F6 (FC, 84 нейрона)
    *   Выход (10 нейронов, для 10 цифр)

**3.3. AlexNet (Krizhevsky et al., 2012)**
*   Значительно более глубокая и широкая версия LeNet.
*   Победитель соревнования ImageNet 2012, что положило начало буму глубокого обучения.
*   **Особенности:**
    *   Использование ReLU в качестве функции активации (вместо сигмоиды/tanh), что ускорило обучение.
    *   Использование Dropout для регуляризации.
    *   Обучение на нескольких GPU (модель была разделена на две части из-за ограничений памяти GPU того времени).
    *   Применение Local Response Normalization (LRN), хотя позже было показано, что Batch Normalization эффективнее.
    *   Использование перекрывающегося пулинга (overlapping pooling).
*   Размер свёрточных ядер уменьшался от входа к выходу (например, с 11x11 до 3x3).

**3.4. VGG-16 и VGG-19 (Simonyan & Zisserman, 2014)**
*   Очень глубокие сети (16 и 19 слоёв соответственно).
*   **Ключевая идея:** Использование очень маленьких свёрточных фильтров (3x3) последовательно. Два свёрточных слоя 3x3 имеют такое же эффективное рецептивное поле, как один слой 5x5, но с меньшим количеством параметров и большей нелинейностью. Три слоя 3x3 эквивалентны одному 7x7.
*   Простая и однородная архитектура: последовательности блоков Conv(3x3)-ReLU, за которыми следует MaxPool(2x2).
*   Большое количество параметров (138 млн для VGG-16, 144 млн для VGG-19).

**3.5. Network in Network (NiN, Lin et al., 2014)**
*   Идея: заменить простые линейные свёрточные фильтры более сложными микро-сетями (например, небольшими многослойными перцептронами, MLPConv) для вычисления карт признаков.
*   Использование Global Average Pooling перед последним полносвязным слоем, что уменьшает количество параметров и переобучение.
*   **1x1 свёртки (Pointwise Convolutions):**
    *   Используются для изменения количества каналов (глубины) без изменения пространственных размеров.
    *   Могут рассматриваться как полносвязные слои, применяемые к каждому пикселю (по глубине).
    *   Используются в NiN и последующих архитектурах (GoogLeNet, ResNet) для уменьшения размерности ("бутылочное горлышко") перед более дорогими свёртками 3x3 или 5x5.
    *   CCCP (Cascaded Cross-Channel Pooling) – одна из идей, связанных с 1x1 свёртками.

**3.6. GoogLeNet / Inception (Szegedy et al., 2014)**
*   Победитель ImageNet 2014.
*   **Inception модуль:** Основной строительный блок. Параллельно применяет свёртки разных размеров (1x1, 3x3, 5x5) и Max Pooling к входной карте признаков. Результаты конкатенируются по глубине.
    *   **Идея:** Объекты на изображении могут иметь разный масштаб. Разные размеры фильтров позволяют захватывать информацию на разных уровнях детализации.
    *   **1x1 свёртки для уменьшения размерности:** Перед свёртками 3x3 и 5x5 (и после Max Pooling) используются 1x1 свёртки для уменьшения числа каналов, что делает Inception модуль более вычислительно эффективным.
*   Использование вспомогательных классификаторов на промежуточных слоях для борьбы с затуханием градиента.
*   Глубокая, но относительно эффективная по числу параметров сеть.

**3.7. ResNet (Residual Network, He et al., 2015)**
*   Победитель ImageNet 2015. Позволила успешно обучать сети глубиной в сотни и даже тысячи слоёв.
*   **Ключевая идея: Остаточные блоки (Residual Blocks).**
    *   Выход блока $H(x)$ вычисляется как $F(x) + x$, где $F(x)$ – это функция, которую обучают несколько слоёв блока, а $x$ – это вход блока (проброшенная "короткая" связь, skip connection).
    *   Это позволяет градиентам легче проходить через глубокие сети и облегчает обучение тождественного отображения (если $F(x)=0$, то $H(x)=x$).
*   Значительно улучшила результаты на многих задачах компьютерного зрения.

**3.8. Сравнение архитектур (слайд 40)**
*   Графики показывают рост точности (Top-1 accuracy на ImageNet) и числа операций/параметров для различных архитектур.
*   Наблюдается тенденция к увеличению глубины и сложности моделей, что приводит к улучшению качества.

---

## 4. Задачи компьютерного зрения

**4.1. Наборы данных (Datasets)**
*   **MNIST:** Рукописные цифры (0-9). 28x28 пикселей, черно-белые.
*   **Fashion-MNIST:** Изображения 10 категорий одежды. 28x28 пикселей, черно-белые. Альтернатива MNIST для тестирования моделей.
*   **CIFAR-10 / CIFAR-100:** Маленькие цветные изображения (32x32 пикселя) 10 или 100 классов соответственно.
*   **ImageNet (ILSVRC - ImageNet Large Scale Visual Recognition Challenge):**
    *   ~1.2 миллиона обучающих изображений, 1000 классов.
    *   Сыграл ключевую роль в развитии глубокого обучения для компьютерного зрения.

**4.2. Основные задачи**
*   **Классификация изображений (Image Classification):** Присвоить изображению одну метку класса (например, "кошка", "собака").
*   **Классификация + Локализация (Classification + Localization):** Классифицировать основной объект на изображении и определить его местоположение с помощью ограничивающей рамки (bounding box).
*   **Детектирование объектов (Object Detection):** Найти и классифицировать все объекты на изображении, указав их ограничивающие рамки.
*   **Сегментация изображений (Image Segmentation):**
    *   **Семантическая сегментация (Semantic Segmentation):** Присвоить каждому пикселю изображения метку класса (например, "дорога", "небо", "автомобиль", "пешеход"). Не различает отдельные экземпляры одного класса.
    *   **Сегментация экземпляров (Instance Segmentation):** Присвоить каждому пикселю метку класса и различить отдельные экземпляры объектов одного класса (например, "пешеход 1", "пешеход 2").

**4.3. Методы для задач сегментации и детектирования**

**Для семантической сегментации:**
*   **Полностью свёрточные сети (Fully Convolutional Networks, FCN):** Заменяют полносвязные слои в конце классификационных CNN на свёрточные, чтобы получить карту предсказаний той же пространственной размерности, что и вход.
*   **Деконволюция / Транспонированная свёртка (Deconvolution / Transposed Convolution):** Операции, обратные свёртке и пулингу, используемые для увеличения пространственного разрешения карт признаков (upsampling) в декодирующей части сетей для сегментации.
    *   **Max Unpooling:** Использует сохраненные индексы максимальных элементов из соответствующего слоя Max Pooling для восстановления карты признаков.
    *   **Transposed Convolution (иногда неточно называют deconvolution):** Обучаемый слой для апсемплинга. Можно представить как свёртку, где ядро "разбрасывает" значения входной карты на большую выходную карту.
*   **U-Net:** Архитектура с симметричным кодировщиком (encoder) и декодировщиком (decoder) и "skip connections" между ними. Кодировщик извлекает признаки, уменьшая разрешение, а декодировщик восстанавливает разрешение, используя признаки из кодировщика для уточнения локализации. Широко используется в медицинской сегментации.

**Для локализации и детектирования объектов:**
*   **Подход с "головами" (Heads):** После общей свёрточной "основы" (backbone), которая извлекает карты признаков, добавляются отдельные "головы" (небольшие полносвязные или свёрточные сети) для разных задач:
    *   **Classification head:** Предсказывает классы объектов.
    *   **Regression head:** Предсказывает координаты ограничивающих рамок.
*   **R-CNN (Regions with CNN features):**
    1.  **Генерация предложений регионов (Region Proposals):** Используется алгоритм (например, Selective Search) для генерации ~2000 потенциальных регионов, где могут находиться объекты.
    2.  **Извлечение признаков CNN:** Каждый регион "выпрямляется" (warped) до фиксированного размера и пропускается через предобученную CNN для извлечения признаков.
    3.  **Классификация регионов:** Признаки подаются на SVM для классификации объектов.
    4.  **Уточнение рамок (Bounding Box Regression):** Обучается регрессор для уточнения координат рамок.
    *   Недостатки: медленный, так как каждый регион обрабатывается отдельно.
*   **Быстрые модификации R-CNN:** Fast R-CNN, Faster R-CNN (с Region Proposal Network).
*   **YOLO (You Only Look Once):**
    *   Обрабатывает изображение за один проход.
    *   Делит изображение на сетку ячеек. Каждая ячейка предсказывает несколько ограничивающих рамок и вероятности классов для этих рамок.
    *   Значительно быстрее R-CNN, позволяет работать в реальном времени.
*   **SSD (Single Shot MultiBox Detector):** Другой однопроходный детектор, использующий признаки из нескольких слоев для детектирования объектов разного масштаба.

---
