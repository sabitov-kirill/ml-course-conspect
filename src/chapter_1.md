# Лекция 1: Глубокое обучение

- [Лекция 1: Глубокое обучение](#лекция-1-глубокое-обучение)
  - [1. Введение в машинное и глубокое обучение](#1-введение-в-машинное-и-глубокое-обучение)
  - [2. Базовое обучаемое преобразование](#2-базовое-обучаемое-преобразование)
  - [3. Функции активации](#3-функции-активации)
  - [4. Остаточные связи (Residual Connections)](#4-остаточные-связи-residual-connections)
  - [5. Декомпозиция моделей и эффективное обучение](#5-декомпозиция-моделей-и-эффективное-обучение)
  - [6. Kolmogorov-Arnold Networks (KAN)](#6-kolmogorov-arnold-networks-kan)

---

## 1. Введение в машинное и глубокое обучение

**1.1. Из чего состоит машинное обучение?**
Задача машинного обучения (МО) состоит из трёх ключевых частей:

* **Набор данных (Dataset):** Выборка объектов из реального мира.
* **Модель (Model):** Функция или структура, которая пытается уловить закономерности в данных.
* **Функция ошибки (Loss Function / Error Function):** Метрика, оценивающая, насколько хорошо модель справляется с задачей. Минимизация этой функции является целью обучения.

| Реальный мир                                | Машинное обучение                    |
| :------------------------------------------ | :----------------------------------- |
| Потенциально бесконечное множество объектов | Набор данных (выборка)               |
| Закономерность или зависимость              | Модель или функция                   |
| Бизнес-метрика                              | Эмпирический риск или функция ошибки |

*Эмпирический риск* – это средняя ошибка модели на обучающей выборке, аппроксимация истинного риска (ожидаемой ошибки на всех возможных данных).

**1.2. Глубокое обучение (Deep Learning, DL) vs. "Классическое" Машинное обучение (ML)**

| Признак                     | Машинное обучение (ML)                                                               | Глубокое обучение (DL)                                                              |
| :-------------------------- | :----------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------- |
| **Тип данных**              | Преимущественно табличные данные                                                     | Сложные сырые данные: изображения, текст, аудио, видео и т.д.                       |
| **Модель (Функция)**        | Часто фиксированная, относительно простая функция (линейные модели, деревья решений) | Почти¹ произвольная, сложная, многослойная функция (нейронные сети)                 |
| **Представление признаков** | Требуется ручное конструирование признаков (feature engineering)                     | Автоматическое извлечение иерархических признаков из сырых данных                   |
| **Функция ошибки**          | Эмпирический риск                                                                    | Часто также эмпирический риск, но оптимизация может быть сложнее из-за невыпуклости |

¹ *Примечание:* Функция должна быть дифференцируемой (или почти везде дифференцируемой), чтобы её можно было обучить методами градиентного спуска.

---

## 2. Базовое обучаемое преобразование

**2.1. Линейная классификация и её ограничения**
Линейный классификатор пытается разделить классы с помощью гиперплоскости. Решение принимается на основе знака скалярного произведения:
$$ y = \text{sign}(\langle x, \theta \rangle + \theta_0) $$
где $x$ – вектор признаков объекта, $\theta$ – вектор весов, $\theta_0$ – сдвиг (bias).

* **Проблема:** Даже простые логические функции, такие как XOR (исключающее ИЛИ), не являются линейно разделимыми.
  * OR: Линейно разделима.
  * XOR: Нелинейно разделима.

**2.2. "Линейность" булевых функций**
Не путать линейную разделимость с линейностью в смысле алгебры Жегалкина (полиномы над GF(2)). Из 16 булевых функций от двух переменных, линейно разделимыми являются 14. Неразделимы XOR и XNOR (эквивалентность).

**2.3. Композиция логических функций (Построение XOR)**
Нелинейно разделимые функции можно реализовать комбинацией линейно разделимых элементов (нейронов) в несколько слоёв. Например, XOR можно представить как:
$$ x_1 \oplus x_2 = (x_1 \lor x_2) \land \neg(x_1 \land x_2) $$
Используя пороговую функцию активации $[z > 0]$ (равна 1 если $z>0$, иначе 0):

* AND: $$x_1 \land x_2 = [x_1 + x_2 - 3/2 > 0]$$
* OR: $$x_1 \lor x_2 = [x_1 + x_2 - 1/2 > 0]$$
* NOT: $$\neg x = [-x + 1/2 > 0]$$
* XOR (один из вариантов): $$x_1 \oplus x_2 = [x_1 + x_2 - 2x_1x_2 - 1/2 > 0]$$ (для $x_i \in \{0,1\}$)
Это основа для многослойных нейронных сетей.

**2.4. Многослойная нейронная сеть (Multilayer Perceptron, MLP)**
Состоит из:

* **Входного слоя (Input Layer):** Принимает признаки объекта.
* **Скрытых слоёв (Hidden Layers):** Выполняют промежуточные вычисления. Каждый нейрон скрытого слоя обычно применяет линейное преобразование к выходам предыдущего слоя, добавляет сдвиг и пропускает результат через нелинейную функцию активации.
* **Выходного слоя (Output Layer):** Формирует предсказание модели.

Интерактивный пример: [playground.tensorflow.org](https://playground.tensorflow.org/)

**2.5. Языковые нюансы (Терминология)**

* **Синонимы MLP:** Multilayer Neural Network, Fully Connected Neural Network (FCNN), Feedforward Neural Network (FNN), Deep Neural Network (DNN), Artificial Neural Network (ANN).
* **Матричное преобразование (один слой):**
    $$ X_{in} \xrightarrow{A_i, b_i, \sigma} X_{out} $$
    1. Умножение на матрицу весов: $$M_i = X_i \cdot A_i$$
    2. Прибавление вектора сдвига: $$S_i = M_i + b_i$$
    3. Применение нелинейной функции активации (поэлементно): $$X_{i+1} = \sigma(S_i)$$
  * $A_i$ – матрица весов (weights).
  * $b_i$ – вектор сдвигов (biases).
  * $\sigma$ – нелинейная функция активации.
* **Термин "Слой":** Исторически архитектуры были строго послойными. Современные архитектуры могут быть произвольными ациклическими графами (DAGs), где "слой" – это скорее блок вычислений.

**2.6. Пакетное вычисление (Batch Computation)**
Для эффективности вычислений (особенно на GPU) и более стабильного обучения, объекты обрабатываются пакетами (батчами).

* Несколько скалярных произведений $\rightarrow$ умножение вектора на матрицу.
* Несколько умножений векторов на матрицу $\rightarrow$ умножение матрицы на матрицу.
* **Тензор:** Многомерный массив (обобщение матриц).

**2.7. Пересчёт производной для одного преобразования (Основа Backpropagation)**
Пусть $i$-е преобразование: $Y_i = f(X_i \cdot A_i + b_i)$.
Обозначим $M_i = X_i \cdot A_i$ и $S_i = M_i + b_i = X_i \cdot A_i + b_i$.
Тогда $Y_i = f(S_i)$.
Производные функции потерь $L$ по параметрам и входам (для одного образца, $\odot$ - поэлементное произведение (Адамара)):

* $$\frac{\partial L}{\partial S_i} = \frac{\partial L}{\partial Y_i} \odot f'(S_i)$$
* $$\frac{\partial L}{\partial b_i} = \frac{\partial L}{\partial S_i}, (суммируется\ по\ батчу,\ если\ b_i\ общий)$$
* $$\frac{\partial L}{\partial M_i} = \frac{\partial L}{\partial S_i}$$
* $$\frac{\partial L}{\partial A_i} = X_i^T \cdot \frac{\partial L}{\partial M_i}$$
* $$\frac{\partial L}{\partial X_i} = \frac{\partial L}{\partial M_i} \cdot A_i^T$$

**2.8. Анализ матричного преобразования**

* Позволяет гибко изменять размерность векторов.
* Сложность модели контролируется числом слоёв и размерами промежуточных векторов.
* Хорошо параллелизуется.
* **Ключевое:** Без нелинейных функций активации ($\sigma$) композиция матричных преобразований эквивалентна одному линейному преобразованию. Нелинейность необходима для увеличения выразительной мощности.

**2.9. Низкоранговое произведение матриц**
Вместо одного преобразования $n \rightarrow m$ с матрицей $A \in \mathbb{R}^{n \times m}$, можно использовать два: $n \rightarrow k \rightarrow m$ с матрицами $A_1 \in \mathbb{R}^{n \times k}$ и $A_2 \in \mathbb{R}^{k \times m}$.
Если $k(n+m) < nm$, это уменьшает число параметров. Это "бутылочное горлышко" (bottleneck layer).

**2.10. Преимущества и проблемы нескольких слоёв**

* **Хорошо:**
  * **Универсальная теорема аппроксимации (Cybenko, 1989):** Сеть с одним скрытым слоем и достаточным числом нейронов может аппроксимировать любую непрерывную функцию с любой точностью.
  * Глубокие сети (много слоёв) часто могут быть более эффективны по числу параметров для сложных функций, чем широкие и неглубокие, так как они могут изучать иерархические представления признаков.
* **Плохо:**
    1. **Проблема симметрии:** Перестановка нейронов в скрытом слое не меняет функцию, что приводит к множеству эквивалентных минимумов функции ошибки.
        * *Решение:* Случайная инициализация весов.
    2. **Проблема затухания градиента (Vanishing Gradient):** В глубоких сетях градиент может экспоненциально уменьшаться при распространении к начальным слоям, замедляя их обучение.
    3. **Проблема взрыва градиента (Exploding Gradient):** Градиент может экспоненциально расти, приводя к нестабильности обучения.
        * *Решения для 2 и 3:*
            * Специальные архитектуры (LSTM, ResNet).
            * Функции активации, не склонные к насыщению (ReLU).
            * Нормализация активаций (Batch Normalization).
            * Тщательная инициализация весов (Xavier, He).
            * Подрезка градиента (Gradient Clipping):
                * Глобальная: если $$\|g\| > c \Rightarrow g_{new} = c \cdot \frac{g_{old}}{\|g\|}$$
                * Локальная: если $$|g_i| > c \Rightarrow g_i = c \cdot \text{sign}(g_i)$$

---

## 3. Функции активации

Функции активации вводят нелинейность в модель, позволяя ей изучать сложные зависимости.

**3.1. Исторический контекст**
Изначально использовалась ступенчатая функция: $$f(x) = \begin{cases} 1 & \text{if } x \ge 0 \\ 0 & \text{if } x < 0 \end{cases}$$. Она не дифференцируема в нуле. Современные функции активации обычно гладкие.

**3.2. Sigmoid (Логистическая функция)**
$$ \sigma(x) = \frac{1}{1+e^{-x}} $$

* Выход: $(0, 1)$.
* Производная: $$\sigma'(x) = \sigma(x)(1-\sigma(x))$$. Максимальное значение $0.25$.
* Проблемы:
  * Насыщение: при больших $|x|$ производная близка к нулю, что ведёт к затуханию градиента.
  * Выход не центрирован около нуля.

**3.3. Tanh (Гиперболический тангенс)**
$$ \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} = 2\sigma(2x) - 1 $$

* Выход: $(-1, 1)$.
* Производная: $$\tanh'(x) = 1 - \tanh^2(x)$$. Максимальное значение $1$.
* Преимущества над Sigmoid: выход центрирован около нуля, что может ускорять сходимость.
* Проблемы: также страдает от насыщения.

**3.4. ReLU (Rectified Linear Unit)**
$$ \text{ReLU}(x) = \max(0, x) $$

* Выход: $[0, \infty)$.
* Производная: $$\text{ReLU}'(x) = \begin{cases} 1 & \text{if } x > 0 \\ 0 & \text{if } x \le 0 \end{cases}$$ (в $x=0$ обычно берут 0 или 1).
* Преимущества:
  * Вычислительно эффективна.
  * Не насыщается для $x > 0$, помогает бороться с затуханием градиента.
  * Приводит к разреженности активаций (многие нейроны "молчат").
* Недостатки:
  * Выход не центрирован около нуля.
  * "Мёртвые ReLU": если нейрон всегда получает на вход отрицательные значения, он перестаёт активироваться и обучаться.

**3.5. Модификации ReLU**

* **Leaky ReLU:** $$ \text{LReLU}(x) = \begin{cases} x & \text{if } x > 0 \\ \alpha x & \text{if } x \le 0 \end{cases} $$ (где $\alpha$ – малая константа, например, 0.01). Позволяет небольшой градиент при $x<0$.
* **Parametric ReLU (PReLU):** $\alpha$ является обучаемым параметром.
* **Exponential Linear Unit (ELU):**
    $$ \text{ELU}_\alpha(x) = \begin{cases} x & \text{if } x \ge 0 \\ \alpha(e^x - 1) & \text{if } x < 0 \end{cases} $$
    Стремится к $-\alpha$ при $x \rightarrow -\infty$. Может давать отрицательные выходы, центрируя активации.

**3.6. Softplus**
$$ \text{Softplus}(x) = \ln(1 + e^x) $$

* Гладкая аппроксимация ReLU. Производная: $$\text{Softplus}'(x) = \sigma(x)$$.
* Вычислительно дороже ReLU.

**3.7. Swish и Mish**

* **Swish (или SiLU - Sigmoid Linear Unit):** $$ \text{Swish}_\beta(x) = x \cdot \sigma(\beta x) $$ (часто $\beta=1$)
* **Mish:** $$ \text{Mish}(x) = x \cdot \tanh(\text{Softplus}(x)) $$
* Более сложные, но могут давать лучшие результаты. Немонотонны.

**3.8. Сводная таблица и связи**

| Название               | Функция $f(x)$         | Производная $f'(x)$                                       |
| :--------------------- | :--------------------- | :-------------------------------------------------------- |
| Sigmoid                | $$\frac{1}{1+e^{-x}}$$ | $$f(x)(1-f(x))$$                                          |
| Tanh                   | $$\tanh(x)$$           | $$1 - f(x)^2$$                                            |
| ReLU (Leaky, $\alpha$) | $$\max(\alpha x, x)$$  | $$\begin{cases} 1 & x>0 \\ \alpha & x \le 0 \end{cases}$$ |
| SoftPlus               | $$\ln(1+e^x)$$         | $$\frac{1}{1+e^{-x}} = \sigma(x)$$                        |
| Arctg                  | $$\text{atan}(x)$$     | $$\frac{1}{1+x^2}$$                                       |
| SoftSign               | $$\frac{x}{1+          | x                                                         | }$$ | $$\frac{1}{(1+ | x | )^2}$$ |

*Связи (концептуально):*

* `sign(x)` (ступенька в -1,1) $\xrightarrow{\text{сглаживание}}$ `tanh(x)`
* `I[x>0]` (ступенька в 0,1) $\xrightarrow{\text{сглаживание}}$ `sigmoid(x)`
* `I[x>0]` (ступенька в 0,1) $\xrightarrow{\text{интегрирование}}$ `ReLU(x)`
* `ReLU(x)` $\xrightarrow{\text{сглаживание}}$ `Softplus(x)`

---

## 4. Остаточные связи (Residual Connections)

Идея борьбы с затуханием градиента и облегчения обучения очень глубоких сетей.

**4.1. Ранние идеи**

* **LSTM (1997):** Внутреннее состояние ячейки ($C_t$) обновляется аддитивно ($C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t$), что позволяет градиентам проходить без затухания через множество временных шагов.
* **Активация с линейным компонентом (LeCun, 1998):** $$f(x) = \tanh(x) + ax$$. Добавление линейного "прохода" помогает избежать "плоских участков" (где градиент мал).
* **GoogLeNet (2015):** Использование вспомогательных классификаторов на промежуточных слоях для "проталкивания" градиента вглубь сети.

**4.2. ResNet (Residual Network, 2016)**
Ключевая идея: обучать **остаточную функцию** $F(x)$ вместо直接 отображения $H(x)$.
Слой (или блок слоёв) вычисляет $F(x)$, а его выход складывается с входом $x$:
$$ H(x) = F(x) + x $$
Если $x$ и $F(x)$ имеют разную размерность, $x$ преобразуется (например, проекцией).

* **Преимущества:**
  * Значительно облегчает обучение очень глубоких сетей (сотни, тысячи слоёв).
  * Если какой-то блок не нужен, сеть может "научиться" делать $F(x) \approx 0$, и блок превращается в тождественное отображение.
  * Градиенты могут проходить напрямую через тождественные связи.

---

## 5. Декомпозиция моделей и эффективное обучение

**5.1. Перенос знаний (Transfer Learning)**

1. Обучить модель ($A$) на большом общем наборе данных ($D_A$) для общей задачи ($T_A$).
2. Взять часть обученной модели ($A'$, например, все слои кроме последнего) в качестве экстрактора признаков.
3. Добавить к $A'$ новые слои ($B$) и обучить их (или всю конструкцию $A'+B$) на меньшем, специфичном наборе данных ($D_B$) для специфичной задачи ($T_B$).

**5.2. Дообучение (Fine-tuning)**
При переносе знаний:

1. **Заморозка:** Параметры предобученной части ($A'$) замораживаются (не обновляются). Обучаются только новые слои ($B$). Это предотвращает "разрушение" хороших весов $A'$ необученными слоями $B$.
2. **Разморозка (опционально):** После обучения $B$, можно разморозить $A'$ и дообучить всю сеть (часто с меньшей скоростью обучения для $A'$), чтобы адаптировать и предобученные признаки.

**5.3. Low-Rank Adaptation (LoRA)**
Метод параметр-эффективного дообучения. Вместо обновления всех весов $W_0$ предобученной модели, $W_0$ замораживается, и обучается низкоранговое "дельт"-изменение $\Delta W = B \cdot A$, где $A$ и $B$ – две маленькие матрицы.
$$ h' = W_0 x + B A x $$
После обучения $W_0$ и $BA$ можно слить: $W_{new} = W_0 + BA$. Значительно уменьшает количество обучаемых параметров.

**5.4. Послойное обучение (Layer-wise Training)**
Метод обучения, при котором слои добавляются и обучаются последовательно:

1. Обучить $f_1$.
2. Заморозить $f_1$, добавить $f_2$, обучить $f_2$ (входы от $f_1$).
3. И так далее.
Менее популярен сейчас, чем end-to-end обучение, но может быть полезен для инициализации или в специфических случаях.

**5.5. Прореживание (Pruning) сетей**
Удаление избыточных весов, нейронов или целых блоков для уменьшения размера модели и ускорения вывода.

* **Прореживание ResNet:** Благодаря остаточным связям, если блок $F(x)$ становится бесполезным ($F(x) \approx 0$), его можно удалить. Оценка "бесполезности" делается на валидационном наборе. После прореживания модель обычно дообучается.
* **Оптимальное прореживание (Optimal Brain Damage, LeCun et al., 1989):**
    Удаляются рёбра (веса), которые наименее важны. Важность параметра $a_i$ (вес) оценивается как:
    $$ L_i = \frac{a_i^2}{[H^{-1}]_{i,i}} $$
    где $H$ – матрица Гессе (матрица вторых производных функции потерь). $[H^{-1}]_{i,i}$ – $i$-й диагональный элемент обратной матрицы Гессе.
    Если вычисление Гессиана затруднительно, используется более простой критерий – **прореживание по величине (magnitude pruning):** удаляются веса с наименьшим абсолютным значением $|a_i|$.

---

## 6. Kolmogorov-Arnold Networks (KAN)

**6.1. Теорема Колмогорова – Арнольда**
Любая непрерывная многомерная функция $f(x_1, \dots, x_n)$ на $[0,1]^n$ может быть представлена в виде:
$$ f(x_1, \dots, x_n) = \sum_{q=0}^{2n} \Phi_q \left( \sum_{p=1}^{n} \phi_{p,q}(x_p) \right) $$
где $\Phi_q$ и $\phi_{p,q}$ – это одномерные непрерывные функции.
*Примечание: в оригинальной теореме верхний предел суммы по $q$ равен $2n+1$.*

**6.2. KAN vs MLP**

* **MLP:** Линейные преобразования (веса) находятся на рёбрах, а фиксированные нелинейные функции активации – на узлах (нейронах).
    $$ \text{MLP}(x) = (W_L \circ \sigma_{L-1} \circ \dots \circ W_2 \circ \sigma_1 \circ W_1)(x) $$
* **KAN:** Обучаемые одномерные функции активации находятся на рёбрах, а узлы выполняют простое суммирование.
    $$ \text{KAN}(x) = (\Phi_L \circ \Phi_{L-1} \circ \dots \circ \Phi_1)(x) $$
    где каждый $\Phi_k$ представляет собой слой KAN, где каждая связь имеет свою обучаемую 1D функцию.
    Обучаемые одномерные функции часто реализуются с помощью B-сплайнов:
    $$ \phi(x) = \sum_j c_j B_j(x) $$
    где $B_j(x)$ – базисные сплайн-функции, а $c_j$ – обучаемые коэффициенты.
    Может также использоваться комбинация: $$\phi(x) = \alpha \cdot \text{silu}(x) + \beta \cdot \text{spline}(x)$$

**6.3. Свойства KAN (заявленные)**

* **Точность и параметр-эффективность:** Могут достигать лучшей точности с меньшим числом параметров по сравнению с MLP на некоторых задачах.
* **Интерпретируемость:** Поскольку обучаемые функции одномерны, их можно легко визуализировать. Иногда они могут соответствовать известным символьным функциям ($x^2$, $\sin(x)$, и т.д.).
* **Меньшая склонность к катастрофическому забыванию:** Локальность сплайнов может помочь лучше сохранять знания о предыдущих задачах.
* **Символьная регрессия:** KAN могут использоваться для поиска символьных формул, описывающих данные, путем идентификации простых функций в выученных сплайнах и их последующей комбинации.

**Процесс символьной регрессии с KAN:**

1. Обучение KAN с регуляризацией для разреживания (удаления неважных связей).
2. Прореживание сети.
3. Идентификация простых символьных функций в оставшихся активных сплайнах (например, $x^2$, $e^x$, $\sin(x)$).
4. Дообучение аффинных параметров (масштаба и сдвига) для этих символьных функций.
5. Формирование итоговой символьной формулы.
6. "Number Snap": Приведение численных коэффициентов к простым дробям или известным константам (например, $3.141 \approx \pi$).

---
