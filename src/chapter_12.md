
# Лекция 12: Генеративные модели

- [Лекция 12: Генеративные модели](#лекция-12-генеративные-модели)
  - [1. Задача генерации новых объектов](#1-задача-генерации-новых-объектов)
  - [2. Авторегрессионные модели](#2-авторегрессионные-модели)
  - [3. Вариационные автокодировщики (Variational Autoencoders, VAE)](#3-вариационные-автокодировщики-variational-autoencoders-vae)
  - [4. Генеративно-состязательные модели (Generative Adversarial Networks, GAN)](#4-генеративно-состязательные-модели-generative-adversarial-networks-gan)
  - [5. Интересные идеи в GAN-ах](#5-интересные-идеи-в-gan-ах)
  - [6. Диффузные модели (Denoising Diffusion Probabilistic Models, DDPM)](#6-диффузные-модели-denoising-diffusion-probabilistic-models-ddpm)

---

## 1. Задача генерации новых объектов

**1.1. Какой это тип задачи?**
Генерация новых объектов, похожих на существующие, но не являющихся их точными копиями, может рассматриваться в контексте разных парадигм МО:
*   **С учителем (Supervised Learning):** Если есть явные метки или условия для генерации (например, "сгенерируй изображение кошки"). Conditional GANs, Text-to-Image модели.
*   **Без учителя (Unsupervised Learning):** Наиболее частый случай. Модель обучается на неразмеченных данных и пытается уловить их внутреннюю структуру и распределение для генерации новых образцов. VAE, большинство GAN, авторегрессионные модели.
*   **Частичное с учителем (Semi-Supervised Learning):** Используются и размеченные, и неразмеченные данные.
*   **С подкреплением (Reinforcement Learning):** Генератор может рассматриваться как агент, получающий вознаграждение за "хорошие" сгенерированные объекты.

**1.2. Определение препятствий для создания новых объектов**
*   **Новизна и принадлежность к множеству:** Сложность зависит от того, как мы определяем "новизну" объекта и как измеряем его "похожесть" на желаемое распределение данных.
*   **Эмпирические правила:** Если можно создать набор правил для генерации (например, процедурная генерация), то машинное обучение может не потребоваться.
*   **Контекст машинного обучения:** Мы хотим, чтобы:
    *   Сгенерированный объект был валидным (например, сгенерированное изображение было осмысленным изображением).
    *   Сгенерированный объект принадлежал к той же **предметной области** (data manifold), что и обучающие данные.
        *   Все детали должны соответствовать предметной области.
        *   Взаимодействие между деталями должно быть реалистичным.

**1.3. Препятствие в контексте машинного обучения**
*   **Проблема обобщения:** Если модель просто запомнит обучающие примеры, учёт (генерация) действительно **новых** объектов маловероятен.
*   **Скрытая структура:** Мы хотим создать объект, который правдоподобен относительно некоторой **скрытой структуры** или **распределения вероятностей** $p_{data}(x)$, лежащего в основе обучающих данных.
*   **Задача обучения без учителя:**
    1.  Изучить скрытую структуру объектов из обучающей выборки.
    2.  Выучить (аппроксимировать) распределение $p_{data}(x)$.
    3.  Сэмплировать (выбирать) новые объекты из выученного распределения $p_{model}(x)$.
    Цель: $p_{model}(x)$ должно быть похоже на $p_{data}(x)$.

**1.4. Как измерить сходство распределений?**
*   **Дивергенция Кульбака-Лейблера (KL-Divergence):**
    $$ D_{KL}(P || Q) = \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} dx $$
    (Для дискретных распределений: $\sum_x p(x) \log \frac{p(x)}{q(x)}$).
    *   $p(x)$ – истинное распределение данных, $q(x)$ – распределение, моделируемое генератором.
    *   Также называется **относительной энтропией** $P$ по отношению к $Q$.
    *   **Несимметрична:** $D_{KL}(P || Q) \ne D_{KL}(Q || P)$. Поэтому это не расстояние в математическом смысле.
    *   $D_{KL}(P || Q) \ge 0$, и $D_{KL}(P || Q) = 0$ только если $P=Q$.
*   Другие меры: расстояние Вассерштейна, Jensen-Shannon дивергенция.

**1.5. Сложности генеративного моделирования**
*   **Оценка плотности $p_{data}(x)$:** Ключевая проблема в обучении без учителя.
    *   **Явная (Explicit) оценка плотности:** Модель напрямую определяет и обучается параметрической форме для $p_{model}(x)$ (например, авторегрессионные модели, VAE).
    *   **Неявная (Implicit) оценка плотности:** Модель обучается генерировать выборку из $p_{model}(x)$ без явного определения самой функции плотности (например, GAN).
*   **Проклятие размерности:** Восстанавливать многомерные распределения (например, для изображений высокого разрешения) очень сложно.

**1.6. Таксономия генеративных моделей (слайд 11)**
Иерархическая классификация подходов:
*   **Верхний уровень:** Maximum Likelihood (явные и неявные модели плотности).
*   **Явные модели плотности (Explicit Density):**
    *   **Вычислимые (Tractable Density):** Плотность можно вычислить аналитически.
        *   Fully visible belief nets (FVBNs, например, авторегрессионные модели как PixelRNN, NADE).
        *   Модели с изменением переменных (Change of variables models / Normalizing Flows).
    *   **Аппроксимированные (Approximate Density):** Плотность аппроксимируется.
        *   **Вариационные (Variational):** VAE.
        *   **Марковские цепи (Markov Chain):** Машины Больцмана.
*   **Неявные модели плотности (Implicit Density):**
    *   **Прямые (Direct):** GAN.
    *   **Марковские цепи (Markov Chain):** GSN (Generative Stochastic Networks).

**1.7. Оценка качества генерации**
*   **Inception Score (IS):**
    *   Использует предобученную классификационную модель Inception.
    *   Для сгенерированных изображений:
        1.  $p(y|x)$: предсказание класса $y$ для сгенерированного изображения $x$.
        2.  $p(y) = \int p(y|x)p_{model}(x)dx$: маргинальное распределение классов.
    *   $IS = \exp(\mathbb{E}_{x \sim p_{model}} [D_{KL}(p(y|x) || p(y))])$.
    *   **Высокий IS означает:**
        *   Низкая энтропия $p(y|x)$ (уверенность в предсказании класса для каждого изображения, т.е. изображения четкие и узнаваемые).
        *   Высокая энтропия $p(y)$ (большое разнообразие генерируемых классов).
*   **Fréchet Inception Distance (FID):**
    *   Сравнивает распределения активаций из некоторого слоя Inception-модели для реальных и сгенерированных изображений.
    *   Предполагается, что эти активации (признаки) следуют многомерному нормальному распределению.
    *   $FID = ||\mu_r - \mu_g||^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})$.
    *   $\mu_r, \Sigma_r$ – среднее и ковариация для реальных данных, $\mu_g, \Sigma_g$ – для сгенерированных.
    *   **Меньшее значение FID указывает на большее сходство** распределений и лучшее качество генерации. Считается более робастной метрикой, чем IS.

---

## 2. Авторегрессионные модели

**2.1. Глубокая сеть доверия (Deep Belief Network - DBN, исторический контекст)**
Хотя DBN не являются авторегрессионными в современном смысле для генерации изображений, идея разложения совместной вероятности важна.
*   Объект $x$ (например, изображение) разбивается на части $x_i$ (например, пиксели).
*   **Явная модель плотности:** Используется цепное правило вероятностей для разложения $p(x)$:
    $$ p(x) = p(x_1) p(x_2|x_1) p(x_3|x_1, x_2) \dots p(x_n|x_1, \dots, x_{n-1}) = \prod_{i=1}^n p(x_i | x_1, \dots, x_{i-1}) $$
*   **Генерация:** Последовательно сэмплируется $x_1 \sim p(x_1)$, затем $x_2 \sim p(x_2|x_1)$ и т.д.
*   **Обучение:** Максимизируется правдоподобие наблюдаемых данных.
*   Условные вероятности $p(x_i | x_{<i})$ моделируются нейронными сетями.

**2.2. PixelRNN**
*   Авторегрессионная модель для генерации изображений пиксель за пикселем.
*   Генерация пикселей изображения обычно начинается с левого верхнего угла и идет по строкам (или по диагоналям).
*   Зависимость текущего пикселя $x_i$ от всех **предыдущих** сгенерированных пикселей $x_{<i}$ моделируется с помощью RNN (например, LSTM, часто двумерной LSTM, сканирующей изображение по двум направлениям).
*   На выходе RNN предсказывает параметры распределения для значения текущего пикселя (например, для RGB – 3 $\times$ 256 классов для каждого канала).

**2.3. PixelCNN**
*   **Проблема PixelRNN:** Последовательная генерация через RNN очень медленная.
*   **Идея PixelCNN:** Использовать свёрточные нейронные сети (CNN) вместо RNN для моделирования зависимостей от предыдущих пикселей.
*   **Маскированные свёртки (Masked Convolutions):** Ядра свёрток конструируются таким образом, чтобы при вычислении активации для пикселя $x_i$ они "видели" только те пиксели, которые были сгенерированы до $x_i$ в выбранном порядке (например, пиксели выше и левее).
*   Генерация по-прежнему последовательная (пиксель за пикселем), но вычисление условных вероятностей на этапе обучения может быть распараллелено (с помощью CNN).

**2.4. Анализ PixelRNN/PixelCNN (Pixel*NN)**
*   **Преимущества:**
    *   Могут явно вычислить правдоподобие $p(x)$ для любого изображения $x$.
    *   Явное правдоподобие обучающих данных дает хорошую и интерпретируемую метрику качества модели (можно сравнивать $log p(x)$).
    *   Генерируют хорошие, четкие образцы (особенно PixelCNN++).
*   **Недостатки:**
    *   **Последовательная генерация очень медленная**, так как каждый пиксель генерируется по одному.

**2.5. Повышение производительности PixelCNN**
*   **Закрытые свёрточные слои (Gated Convolutional Layers):** Использование вентильных механизмов (по аналогии с LSTM/GRU) в свёрточных слоях для лучшего моделирования зависимостей.
*   **Укороченные соединения (Short-cut / Residual Connections):** Облегчают обучение глубоких сетей.
*   **Дискретные логистические потери (Discretized Logistic Mixture Likelihood):** Вместо предсказания 256 классов для каждого пикселя, предсказываются параметры смеси логистических распределений, что лучше моделирует непрерывную природу значений пикселей.
*   **"Мультимасштаб":** Использование признаков с разных уровней разрешения.
*   Различные трюки в процессе обучения (например, планировщики скорости обучения).

---

## 3. Вариационные автокодировщики (Variational Autoencoders, VAE)

(Напоминание структуры автокодировщика: слайд 22)

**3.1. Основная вероятностная идея**
Вместо прямого моделирования сложного распределения данных $p_{data}(x)$, VAE вводит **скрытые (латентные) переменные** $z$, которые, как предполагается, порождают наблюдаемые данные $x$.
$$ p_\theta(x) = \int p_\theta(x|z) p(z) dz $$
*   $p(z)$: Априорное распределение латентных переменных (обычно простое, например, стандартное нормальное $N(0,I)$).
*   $p_\theta(x|z)$: Условное распределение данных при данном $z$ (вероятностная модель декодера), параметризованное $\theta$.
*   Интеграл обычно неразрешим аналитически.

**3.2. Генеративный процесс в VAE**
1.  Сэмплируем латентный вектор $z^{(i)}$ из априорного распределения $p(z)$.
2.  Сэмплируем наблюдаемый вектор $x^{(i)}$ из условного распределения $p_\theta(x|z^{(i)})$ (с помощью декодера).
Декодер $p_\theta(x|z)$ (нейронная сеть) отображает $z$ в параметры распределения для $x$ (например, среднее и дисперсию Гауссианы, если $x$ непрерывный, или параметры Бернулли, если $x$ бинарный).

**3.3. Проблема обучения параметров $\theta$**
Мы хотим максимизировать правдоподобие данных: $\theta^* = \arg \max_\theta \sum_i \log p_\theta(x^{(i)})$.
$\log p_\theta(x) = \log \int p_\theta(x|z) p(z) dz$. Этот интеграл трудноразрешим.
Также трудноразрешима апостериорная вероятность $p_\theta(z|x) = \frac{p_\theta(x|z)p(z)}{p_\theta(x)}$.

**3.4. Введение сети кодировщика (аппроксимация апостериорного распределения)**
Идея: ввести вторую нейронную сеть – **кодировщик (encoder) $q_\phi(z|x)$** – которая аппроксимирует истинное, но трудновычислимое апостериорное распределение $p_\theta(z|x)$.
*   Кодировщик $q_\phi(z|x)$ отображает вход $x$ в параметры распределения для $z$ (например, $\mu_z(x)$ и $\Sigma_z(x)$ для Гауссианы).

**3.5. Сэмплирование с кодировщиком и декодировщиком (во время обучения)**
1.  Для данного $x^{(i)}$ из обучающей выборки, кодировщик $q_\phi(z|x^{(i)})$ выдает параметры $(\mu_z^{(i)}, \Sigma_z^{(i)})$.
2.  Сэмплируем $z^{(i)} \sim N(\mu_z^{(i)}, \Sigma_z^{(i)})$.
3.  Декодер $p_\theta(x|z^{(i)})$ используется для восстановления $\hat{x}^{(i)}$.

**3.6. Вывод функции потерь (Evidence Lower Bound, ELBO)**
Рассмотрим $\log p_\theta(x^{(i)})$. Используя $q_\phi(z|x^{(i)})$, можно показать:
$$ \log p_\theta(x^{(i)}) = \mathbb{E}_{z \sim q_\phi(z|x^{(i)})} [\log p_\theta(x^{(i)}|z)] - D_{KL}(q_\phi(z|x^{(i)}) || p(z)) + D_{KL}(q_\phi(z|x^{(i)}) || p_\theta(z|x^{(i)})) $$
Так как $D_{KL}(\cdot || \cdot) \ge 0$, то:
$$ \log p_\theta(x^{(i)}) \ge \underbrace{\mathbb{E}_{z \sim q_\phi(z|x^{(i)})} [\log p_\theta(x^{(i)}|z)] - D_{KL}(q_\phi(z|x^{(i)}) || p(z))}_{\mathcal{L}(x^{(i)}, \theta, \phi) \text{ - ELBO}} $$
Эта нижняя граница (ELBO) и максимизируется при обучении VAE.
*   **Первый член (реконструкция):** $\mathbb{E}_{z \sim q_\phi(z|x^{(i)})} [\log p_\theta(x^{(i)}|z)]$. Это ожидаемое логарифмическое правдоподобие восстановления $x^{(i)}$ из $z$, сэмплированного из $q_\phi(z|x^{(i)})$. Поощряет точное восстановление.
*   **Второй член (регуляризация):** $D_{KL}(q_\phi(z|x^{(i)}) || p(z))$. KL-дивергенция между аппроксимированным апостериорным распределением $q_\phi(z|x^{(i)})$ и априорным $p(z)$. Заставляет $q_\phi(z|x^{(i)})$ быть близким к $p(z)$ (например, к стандартной Гауссиане), что делает латентное пространство более гладким и структурированным.

**3.7. Обучение VAE**
*   Максимизируем ELBO $\mathcal{L}(x^{(i)}, \theta, \phi)$ по параметрам $\theta$ (декодер) и $\phi$ (кодировщик).
*   **Репараметризационный трюк (Reparameterization Trick):** Чтобы градиент мог проходить через процесс сэмплирования $z \sim q_\phi(z|x)$, если $q_\phi(z|x)$ – Гауссиана $N(\mu_z(x), \Sigma_z(x))$, то $z$ сэмплируется как $z = \mu_z(x) + \epsilon \cdot \sqrt{\Sigma_z(x)}$, где $\epsilon \sim N(0,I)$. Теперь $\mu_z$ и $\Sigma_z$ детерминистически зависят от $x$ и $\phi$.
*   Для каждого мини-батча: прямой проход для вычисления ELBO, затем обратный проход для обновления $\theta, \phi$.

**3.8. Создание данных с помощью обученного VAE**
Используется только декодер:
1.  Сэмплируем $z \sim p(z)$ (например, из $N(0,I)$).
2.  Генерируем $\hat{x} \sim p_\theta(x|z)$ (пропускаем $z$ через декодер, чтобы получить параметры распределения для $x$, и сэмплируем $x$).

**3.9. Анализ VAE**
*   **Преимущества:**
    *   Принципиальный вероятностный подход к генеративным моделям.
    *   Дает возможность получить осмысленное латентное пространство $q_\phi(z|x)$, которое может быть полезно для других задач (например, как экстрактор признаков).
    *   Позволяет явно вычислять (аппроксимацию) правдоподобия данных.
*   **Недостатки:**
    *   Максимизация ELBO – это не то же самое, что максимизация истинного правдоподобия. Качество оценки правдоподобия не такое высокое, как у PixelRNN/PixelCNN.
    *   Генерируемые образцы часто **более размытые** и менее качественные по сравнению с GAN. Это связано с тем, что член реконструкции в ELBO (часто MSE для непрерывных данных) поощряет усреднение, а KL-член может слишком сильно "сглаживать" латентное пространство.

---

## 4. Генеративно-состязательные модели (Generative Adversarial Networks, GAN)

**4.1. Основные идеи**
*   Не пытаться непосредственно моделировать или аппроксимировать распределение плотности $p_{data}(x)$.
*   Обучать **преобразование (генератор)**, которое отображает случайный шум $z$ (из простого априорного распределения, например, $N(0,I)$) в объекты $x$, похожие на реальные.
*   Использовать **теоретико-игровой подход**: состязание двух нейронных сетей.

**4.2. Генератор vs Дискриминатор**
*   **Генератор ($G$):** Нейронная сеть, которая генерирует объекты $x_{gen} = G(z)$, пытаясь "обмануть" дискриминатор, чтобы он принял их за настоящие.
*   **Дискриминатор ($D$):** Нейронная сеть, которая обучается отличать настоящие объекты $x_{real}$ (из обучающей выборки) от сгенерированных объектов $x_{gen}$. Выдает вероятность того, что входной объект является настоящим.
*   Обучение построено как противоборство (минимаксная игра) этих двух "игроков".

**4.3. Обучение GAN-ов (слайд 38)**
*   Генератор получает на вход случайный шум $z$ и производит сэмпл $G(z)$.
*   Дискриминатор получает на вход либо реальные изображения из датасета, либо сгенерированные генератором.
*   Обе сети являются дифференцируемыми модулями.

**4.4. Минимаксная игра**
Целевая функция (value function $V(D,G)$) для GAN:
$$ \min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] $$
*   $D(x)$: вероятность того, что дискриминатор считает $x$ настоящим.
*   $G(z)$: объект, сгенерированный из шума $z$.
*   $p_{data}(x)$: распределение реальных данных.
*   $p_z(z)$: априорное распределение шума (например, Гауссиана).

*   **Дискриминатор $D$ (с параметрами $\theta_d$) пытается максимизировать эту функцию:**
    *   $D(x_{real}) \rightarrow 1$ (правильно классифицировать реальные как реальные).
    *   $D(G(z)) \rightarrow 0$ (правильно классифицировать сгенерированные как поддельные).
*   **Генератор $G$ (с параметрами $\theta_g$) пытается минимизировать эту функцию** (эквивалентно, заставить $D(G(z)) \rightarrow 1$, т.е. обмануть дискриминатор).

**4.5. Поочередное обучение**
На практике $D$ и $G$ обучаются поочередно:
1.  **Градиентный подъем по дискриминатору:**
    Фиксируем $G$, обновляем $D$ для максимизации $V(D,G)$.
    $$ \max_{\theta_d} \left( \mathbb{E}_{x \sim p_{data}}[\log D_{\theta_d}(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D_{\theta_d}(G_{\theta_g}(z)))] \right) $$
    Обычно делается несколько шагов обновления $D$ на один шаг $G$.
2.  **Градиентный спуск по генератору:**
    Фиксируем $D$, обновляем $G$ для минимизации $V(D,G)$.
    $$ \min_{\theta_g} \mathbb{E}_{z \sim p_z(z)}[\log(1 - D_{\theta_d}(G_{\theta_g}(z)))] $$

**4.6. Проблема с обучением генератора (насыщение градиента)**
*   Когда дискриминатор очень хорошо отличает подделки ($D(G(z)) \approx 0$), то $\log(1 - D(G(z)))$ очень близок к $\log(1) = 0$, и его градиент по $\theta_g$ становится очень маленьким (насыщается). Генератор плохо обучается.
*   **Решение (изменение обучения генератора):** Вместо минимизации $\mathbb{E}[\log(1 - D(G(z)))]$, генератор максимизирует $\mathbb{E}[\log D(G(z))]$.
    $$ \max_{\theta_g} \mathbb{E}_{z \sim p_z(z)}[\log D_{\theta_d}(G_{\theta_g}(z))] $$
    Эта функция потерь имеет более сильные градиенты, когда $G$ плохо справляется (т.е. когда $D(G(z))$ мало).
*   Графики (слайды 41, 42) показывают, что $\log D(G(z))$ (или $-\log D(G(z))$ при минимизации) дает лучший сигнал градиента, когда $D(G(z))$ мало (sample is likely fake), по сравнению с $\log(1-D(G(z)))$.

**4.7. Шаги обучения (визуализация)**
*   **Шаг обучения дискриминатора (слайд 43):** Параметры генератора "заморожены". Дискриминатор обучается на реальных и сгенерированных примерах. Обратное распространение ошибки для обновления весов дискриминатора.
*   **Шаг обучения генератора (слайд 44):** Параметры дискриминатора "заморожены". Генератор производит образцы, они проходят через дискриминатор. Обратное распространение ошибки (через дискриминатор до генератора) для обновления весов генератора, чтобы он лучше "обманывал" дискриминатор.

**4.8. Динамика обучения (слайд 45)**
Обучение GAN – это поиск равновесия Нэша в игре между $G$ и $D$. В идеале $p_{model}$ (распределение, генерируемое $G$) сходится к $p_{data}$, и $D(x) = 0.5$ везде. Однако на практике сходимость не гарантирована.

**4.9. Недостатки GANs**
*   **Нет гарантии равновесия/сходимости:** Обучение может быть нестабильным.
*   **Схлопывание мод (Mode Collapse):** Генератор может научиться производить только очень ограниченное разнообразие образцов (например, только один или несколько типов изображений из многообразного датасета), которые хорошо обманывают дискриминатор. Он "забывает" о других модах распределения данных.
*   **Осцилляции:** Параметры $G$ и $D$ могут осциллировать, не достигая стабильной точки.
*   **Нет индикатора, когда останавливаться:** Сложно определить, когда модель достаточно обучилась, так как функция потерь не всегда коррелирует с качеством генерируемых изображений. Требуется визуальная оценка или использование метрик (IS, FID).

**4.10. Mode collapse и осцилляции (визуализация, слайд 47)**
Показано, как генератор может начать с воспроизведения шума, затем сфокусироваться на одной моде данных, а затем осциллировать между разными модами или генерировать некачественные образцы.

---

## 5. Интересные идеи в GAN-ах

**5.1. Conditional GANs (cGANs)**
*   **Идея:** Добавить дополнительную информацию (условие, метку класса $y$) как генератору, так и дискриминатору.
    *   Генератор: $G(z,y)$ генерирует объект класса $y$ из шума $z$.
    *   Дискриминатор: $D(x,y)$ оценивает, является ли $x$ реальным объектом класса $y$.
*   Это позволяет генерировать объекты, принадлежащие к определенному классу или обладающие определенными атрибутами.
*   **Целевая функция для cGAN:**
    $$ \min_G \max_D V(D,G) = \mathbb{E}_{(x,y) \sim p_{data}(x,y)}[\log D(x,y)] + \mathbb{E}_{z \sim p_z(z), y \sim p_y(y)}[\log(1 - D(G(z,y),y))] $$
    (Предполагается, что $y$ для генератора сэмплируется из того же распределения, что и метки реальных данных).
*   Дискриминатор теперь должен не только отличать реальное от поддельного, но и проверять соответствие объекта метке $y$.

**5.2. Задача оптимального перемещения и Расстояние Вассерштейна (Wasserstein Distance)**
*   KL-дивергенция и Jensen-Shannon дивергенция (на которой основана оригинальная функция потерь GAN) могут быть не лучшими способами измерения "расстояния" между распределениями, особенно если их носители не пересекаются (что часто бывает на ранних этапах обучения GAN). Это может приводить к проблемам с градиентами.
*   **Расстояние Вассерштейна (Earth Mover's Distance):** Интуитивно, минимальная "стоимость" превращения одного распределения в другое (как перемещение кучи земли).
    $$ W(p_{data}, p_{gen}) = \inf_{\gamma \in \Pi(p_{data}, p_{gen})} \mathbb{E}_{(x,y) \sim \gamma} [||x-y||] $$
    где $\Pi(p_{data}, p_{gen})$ – множество всех совместных распределений $\gamma(x,y)$, чьи маргинальные распределения равны $p_{data}$ и $p_{gen}$ соответственно.
*   **WGAN (Wasserstein GAN):**
    *   Использует расстояние Вассерштейна в качестве функции потерь.
    *   Благодаря двойственности Канторовича-Рубинштейна, $W(p_{data}, p_{gen})$ можно оценить как:
        $$ W(p_{data}, p_{gen}) = \sup_{||f||_L \le 1} ( \mathbb{E}_{x \sim p_{data}}[f(x)] - \mathbb{E}_{x \sim p_{gen}}[f(x)] ) $$
        где супремум берется по всем 1-Липшицевым функциям $f$.
    *   Дискриминатор (называемый **критиком** в WGAN) обучается аппроксимировать эту функцию $f$.
    *   Для обеспечения Липшицевости, веса критика "обрезаются" (weight clipping) до небольшого диапазона, или используется градиентный штраф (gradient penalty, WGAN-GP).
    *   WGAN часто приводит к более стабильному обучению и помогает бороться с mode collapse.

**5.3. Прогрессивное обучение GAN (Progressive GAN, ProGAN)**
*   **Идея:** Начинать генерацию изображений очень низкого разрешения (например, 4x4), а затем постепенно добавлять слои как в генератор, так и в дискриминатор, увеличивая разрешение генерируемых изображений (8x8, 16x16, ..., 1024x1024).
*   Это позволяет модели сначала научиться глобальной структуре, а затем добавлять детали.
*   Приводит к генерации высококачественных изображений высокого разрешения. (Слайд 52, 53 - примеры лиц, сгенерированных StyleGAN, наследником ProGAN).

**5.4. CycleGAN (Обучение на непарных данных)**
*   **Задача:** Преобразование изображений из одного домена в другой без наличия парных обучающих примеров (например, превратить фото лошади в зебру, лето в зиму).
*   Использует два генератора ($G_{A \rightarrow B}$ и $G_{B \rightarrow A}$) и два дискриминатора ($D_A$ и $D_B$).
*   **Ключевая идея: Циклическая согласованность (Cycle Consistency Loss).**
    Если изображение из домена A перевести в домен B ($X_B = G_{A \rightarrow B}(X_A)$), а затем обратно в домен A ($\hat{X}_A = G_{B \rightarrow A}(X_B)$), то результат $\hat{X}_A$ должен быть близок к исходному $X_A$. И наоборот.
    $$ L_{cyc}(G_{A \rightarrow B}, G_{B \rightarrow A}) = \mathbb{E}_{x_A \sim p_A}[||G_{B \rightarrow A}(G_{A \rightarrow B}(x_A)) - x_A||_1] + \mathbb{E}_{x_B \sim p_B}[||G_{A \rightarrow B}(G_{B \rightarrow A}(x_B)) - x_B||_1] $$
*   Общая функция потерь включает стандартные состязательные потери для $G_{A \rightarrow B}$ (с $D_B$) и $G_{B \rightarrow A}$ (с $D_A$), а также циклическую потерю.

**5.5. Доменная адаптация с помощью состязательного обучения (слайд 55)**
*   **Задача:** Адаптировать модель, обученную на одном (source) домене, для работы на другом, но похожем (target) домене, где размеченных данных мало или нет.
*   **Идея:** Обучить экстрактор признаков $G_f$ так, чтобы он генерировал представления, для которых **доменный классификатор $G_d$ не мог бы отличить, из какого домена (source или target) пришел исходный объект**.
*   Экстрактор признаков $G_f$ обучается минимизировать потери на основной задаче (например, классификации $G_y$ на source домене) и **максимизировать** потери доменного классификатора $G_d$ (через градиентный реверсивный слой, gradient reversal layer, который меняет знак градиента при обратном распространении).
*   Это заставляет $G_f$ учить признаки, инвариантные к домену.

---

## 6. Диффузные модели (Denoising Diffusion Probabilistic Models, DDPM)

**6.1. Общая схема обучения**
*   **Идея:** Основана на двух процессах:
    1.  **Прямой процесс (диффузия, фиксированный):** К исходному изображению $x_0$ итеративно (на протяжении $T$ шагов) добавляется небольшой Гауссовский шум, постепенно превращая его в чистый шум $x_T \sim N(0,I)$.
        $$ q(x_t | x_{t-1}) = N(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I) $$
        где $\beta_t$ – небольшой параметр, контролирующий уровень шума на шаге $t$.
        Можно напрямую сэмплировать $x_t$ из $x_0$: $q(x_t|x_0) = N(x_t; \sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)I)$, где $\alpha_t = 1-\beta_t$ и $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$.
    2.  **Обратный процесс (денормализация, обучаемый):** Нейронная сеть $p_\theta(x_{t-1}|x_t)$ обучается обращать этот процесс – предсказывать (восстанавливать) менее зашумленное изображение $x_{t-1}$ из более зашумленного $x_t$.
        Цель – научиться предсказывать шум $\epsilon_\theta(x_t, t)$, добавленный на шаге $t$, чтобы получить $x_0$.
*   **Обучение:** Модель (обычно U-Net архитектура) обучается предсказывать шум $\epsilon$, добавленный к $x_0$ для получения $x_t$, на каждом шаге $t$. Функция потерь:
    $$ L = \mathbb{E}_{t, x_0, \epsilon} [||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon, t)||^2] $$
*   **Генерация (сэмплирование):**
    1.  Начинаем с чистого шума $x_T \sim N(0,I)$.
    2.  Итеративно (от $t=T$ до $1$) сэмплируем $x_{t-1}$ из $p_\theta(x_{t-1}|x_t)$, используя предсказанный моделью шум $\epsilon_\theta(x_t, t)$ для "очистки" $x_t$.
*   Можно добавить **условие $y$** (например, текстовое описание или метку класса) в модель $\epsilon_\theta(x_t, t, y)$ для условной генерации.

**6.2. Трилемма генеративного обучения (слайд 58)**
Разные классы генеративных моделей имеют разные компромиссы между тремя желаемыми свойствами:
*   **Высокое качество сэмплов (High Quality Samples):** Насколько реалистичны и детализированы генерируемые объекты.
    *   Хорошо: GAN, Диффузные модели.
    *   Хуже: VAE, некоторые авторегрессионные.
*   **Быстрое сэмплирование (Fast Sampling):** Насколько быстро можно генерировать новые объекты.
    *   Хорошо: GAN (один проход через генератор), VAE.
    *   Медленно: Авторегрессионные модели (последовательная генерация), Диффузные модели (требуют много итеративных шагов денормализации).
*   **Покрытие мод / Разнообразие (Mode Coverage / Diversity):** Насколько хорошо модель способна генерировать все типы объектов из обучающего распределения, а не только самые частые или простые.
    *   Хорошо: VAE, Нормализующие потоки, Авторегрессионные модели (благодаря явной оценке правдоподобия).
    *   Проблема: GAN (mode collapse). Диффузные модели обычно лучше GAN в этом аспекте.

*   **GANs:** Хорошее качество, быстрое сэмплирование, но проблемы с покрытием мод и стабильностью обучения.
*   **Denoising Diffusion Models:** Очень высокое качество, хорошее покрытие мод, но медленное сэмплирование.
*   **Variational Autoencoders, Normalizing Flows:** Хорошее покрытие мод, быстрое сэмплирование (для VAE), но качество может быть ниже (размытость для VAE).

---
